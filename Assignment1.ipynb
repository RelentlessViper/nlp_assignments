{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIgM6C9HYUhm"
      },
      "source": [
        "### Context-sensitive Spelling Correction\n",
        "\n",
        "The goal of the assignment is to implement context-sensitive spelling correction. The input of the code will be a set of text lines and the output will be the same lines with spelling mistakes fixed.\n",
        "\n",
        "Submit the solution of the assignment to Moodle as a link to your GitHub repository containing this notebook.\n",
        "\n",
        "Useful links:\n",
        "- [Norvig's solution](https://norvig.com/spell-correct.html)\n",
        "- [Norvig's dataset](https://norvig.com/big.txt)\n",
        "- [Ngrams data](https://www.ngrams.info/download_coca.asp)\n",
        "\n",
        "Grading:\n",
        "- 60 points - Implement spelling correction\n",
        "- 20 points - Justify your decisions\n",
        "- 20 points - Evaluate on a test set\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-vb8yFOGRDF"
      },
      "source": [
        "## Implement context-sensitive spelling correction\n",
        "\n",
        "Your task is to implement context-sensitive spelling corrector using N-gram language model. The idea is to compute conditional probabilities of possible correction options. For example, the phrase \"dking sport\" should be fixed as \"doing sport\" not \"dying sport\", while \"dking species\" -- as \"dying species\".\n",
        "\n",
        "The best way to start is to analyze [Norvig's solution](https://norvig.com/spell-correct.html) and [N-gram Language Models](https://web.stanford.edu/~jurafsky/slp3/3.pdf).\n",
        "\n",
        "When solving this task, we expect you'll face (and successfully deal with) some problems or make up the ideas of the model improvement. Some of them are: \n",
        "\n",
        "- solving a problem of n-grams frequencies storing for a large corpus;\n",
        "- taking into account keyboard layout and associated misspellings;\n",
        "- efficiency improvement to make the solution faster;\n",
        "- ...\n",
        "\n",
        "Please don't forget to describe such cases, and what you decided to do with them, in the Justification section.\n",
        "\n",
        "##### IMPORTANT:  \n",
        "Your project should not be a mere code copy-paste from somewhere. You must provide:\n",
        "- Your implementation\n",
        "- Analysis of why the implemented approach is suggested\n",
        "- Improvements of the original approach that you have chosen to implement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import necessary dependencites\n",
        "from collections import Counter, defaultdict\n",
        "from copy import deepcopy\n",
        "import pandas as pd\n",
        "import random\n",
        "import re\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Xb_twOmVsC6"
      },
      "source": [
        "<a id=\"ngram-dataset\"></a>\n",
        "### Which ngram dataset to use?\n",
        "I decided to use the provided fivegram dataset do to its relatively large size and a \"room\" to play. From my perspective, five words IS better than three words.\n",
        "\n",
        "### What is the main idea for my version of solving the given task?\n",
        "It is simple:\n",
        "- Create a basic Norvig's Corrector implementation - A good baseline for us;\n",
        "- Modify the basic Norvig's Corrector by adding N-Gram model inside;\n",
        "- Compare the results;\n",
        "- Think of possible improvements for my solution.\n",
        "\n",
        "### What kind of modifications were made to improve basic Norvig's Corrector implementation?\n",
        "I decided to create a resulting probability for each candidate by summing up two calculated probabilities:\n",
        "- Norvig's Corrector probability;\n",
        "- N-Gram model probability;\n",
        "- Many more discussed at the end of this notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46rk65S4GRSe"
      },
      "source": [
        "## Evaluate on a test set\n",
        "\n",
        "Your task is to generate a test set and evaluate your work. You may vary the noise probability to generate different datasets with varying compexity (or just take another dataset). Compare your solution to the Norvig's corrector, and report the accuracies."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Norvig's Corrector implementation\n",
        "\n",
        "We will use provided fivegram dataset for evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Read the main file and store lines as lists in list\n",
        "text_storage = []\n",
        "\n",
        "with open('/home/viper/Data_science/NLP/assignments/assignment_1/useful_data/fivegrams.txt', 'r') as f:\n",
        "    for string in f.readlines():\n",
        "        text_storage.append(list(map(lambda x: x.lower(), string.split()[1:])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split text storage into training and validation sets\n",
        "train_storage, val_storage = train_test_split(text_storage, test_size=0.1)\n",
        "del text_storage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to calculate the amount of each word in text\n",
        "def calculate_amount(text: list[list[str]]) -> Counter:\n",
        "    counter = Counter()\n",
        "    for inner_list in text:\n",
        "        counter.update(inner_list)\n",
        "    \n",
        "    return counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_counter = calculate_amount(train_storage)\n",
        "val_counter = calculate_amount(val_storage)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('the', 400974),\n",
              " ('to', 260703),\n",
              " ('of', 241476),\n",
              " ('a', 158344),\n",
              " ('in', 113456),\n",
              " ('and', 98590),\n",
              " ('that', 89322),\n",
              " ('i', 65972),\n",
              " (\"n't\", 65604),\n",
              " ('it', 62704)]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_counter.most_common()[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('the', 44762),\n",
              " ('to', 28954),\n",
              " ('of', 27009),\n",
              " ('a', 17555),\n",
              " ('in', 12657),\n",
              " ('and', 10942),\n",
              " ('that', 9796),\n",
              " ('i', 7335),\n",
              " (\"n't\", 7294),\n",
              " ('it', 6997)]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "val_counter.most_common()[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Implement Norvig's spelling corrector\n",
        "class NorvigCorrector():\n",
        "    def __init__(self, train_dict: Counter) -> None:\n",
        "        \"\"\"\n",
        "        Initialize the NorvigCorrector class.\n",
        "        Implementation taken from: https://norvig.com/spell-correct.html\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        train_dict: Counter:\n",
        "            Counter object that contains the amount of each word that is encountered in training text.\n",
        "            For example:\n",
        "            ('the', 401257),\n",
        "            ('to', 260604),\n",
        "            ('of', 241419),\n",
        "            ('a', 158322),\n",
        "            ('in', 113517),\n",
        "            etc.\n",
        "        \n",
        "        Returns\n",
        "        ----------\n",
        "        NorvigCorrector class object.\n",
        "        \"\"\"\n",
        "\n",
        "        self.train_dict = train_dict\n",
        "        self.N = sum(train_dict.values())\n",
        "    \n",
        "    def P(self, word: str, N: int=None) -> float:\n",
        "        \"\"\"\n",
        "        Calculate probability of given word.\n",
        "        \"\"\"\n",
        "\n",
        "        if N is None:\n",
        "            N = self.N\n",
        "        \n",
        "        return self.train_dict[word] / N\n",
        "    \n",
        "    def correction(self, word: str) -> str:\n",
        "        \"\"\"\n",
        "        Find most probable spelling correction for given word.\n",
        "        \"\"\"\n",
        "\n",
        "        return max(self.candidates(word), key=self.P)\n",
        "    \n",
        "    def candidates(self, word: str) -> set:\n",
        "        \"\"\"\n",
        "        Generate possible spelling corrections for given word.\n",
        "        \"\"\"\n",
        "\n",
        "        return (self.known([word]) or (self.known(self.edits1(word)))\n",
        "                or self.known(self.edits2(word)) or [word])\n",
        "    \n",
        "    def known(self, words: str | list[str]) -> set:\n",
        "        \"\"\"\n",
        "        Find the subset of words that appear in the dictionary of `NorvigCorrector.train_words`.\n",
        "        \"\"\"\n",
        "\n",
        "        return set(w for w in words if w in self.train_dict.keys())\n",
        "    \n",
        "    def edits1(self, word: str) -> set:\n",
        "        \"\"\"\n",
        "        Generate all possible edits that are one edit away from given word.\n",
        "        \"\"\"\n",
        "\n",
        "        letters = 'abcdefghijklmnopqrstuvwxyz'\n",
        "        splits = [(word[:i], word[i:]) for i in range(len(word) + 1)]\n",
        "        deletes = [L + R[1:] for L, R in splits if R]\n",
        "        transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R) > 1]\n",
        "        replaces = [L + c + R[1:] for L, R in splits if R for c in letters]\n",
        "        inserts = [L + c + R for L, R in splits for c in letters]\n",
        "\n",
        "        return set(deletes + transposes + replaces + inserts)\n",
        "    \n",
        "    def edits2(self, word: str) -> set:\n",
        "        \"\"\"\n",
        "        Generate all possible edits that are two edits away from given word.\n",
        "        \"\"\"\n",
        "\n",
        "        return (e2 for e1 in self.edits1(word) for e2 in self.edits1(e1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 359,
      "metadata": {},
      "outputs": [],
      "source": [
        "norvig_corrector = NorvigCorrector(train_counter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 360,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'being'"
            ]
          },
          "execution_count": 360,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Test Norvig Corrector\n",
        "norvig_corrector.correction('eing')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Generate a proper validation set for our models\n",
        "\n",
        "The core idea is the following:\n",
        "- Take each word in `val_storage` that has at least one neighboring word from each side (so, we take only 3 words from each list inside `val_storage`);\n",
        "- Modify one taken word once or twice (modifications are chosen randomly)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[['that', 'might', 'be', 'interpreted', 'as'],\n",
              " ['made', 'a', 'lot', 'of', 'sacrifices'],\n",
              " ['plant', 'biological', 'and', 'molecular', 'processes'],\n",
              " ['no', 'reason', 'why', 'they', 'should'],\n",
              " ['and', 'he', 'told', 'her', 'he'],\n",
              " ['out', 'of', 'the', 'sight', 'of'],\n",
              " ['i', 'knew', 'how', 'to', 'work'],\n",
              " ['up', 'out', 'of', 'the', 'mud'],\n",
              " ['then', 'he', 'is', 'going', 'to'],\n",
              " ['of', 'the', 'small', 'sample', 'size']]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "val_storage[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "939841"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_storage)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 314,
      "metadata": {},
      "outputs": [],
      "source": [
        "def random_delete(word: str) -> str:\n",
        "    \"\"\"\n",
        "    Randomly delete one character from the given word.\n",
        "    \"\"\"\n",
        "\n",
        "    if len(word) <= 2:\n",
        "        selected_char = 0\n",
        "    else:\n",
        "        selected_char = random.randint(0, len(word) - 1)\n",
        "\n",
        "    return word[:selected_char] + word[selected_char + 1:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 315,
      "metadata": {},
      "outputs": [],
      "source": [
        "def random_transpose(word: str) -> str:\n",
        "    \"\"\"\n",
        "    Randomly change two adjacent characters in the given word.\n",
        "    \"\"\"\n",
        "\n",
        "    if len(word) <= 1:\n",
        "        return word\n",
        "\n",
        "    if len(word) == 2:\n",
        "        selected_char = 0\n",
        "    else:\n",
        "        selected_char = random.randint(1, len(word) - 1)\n",
        "\n",
        "    return word[:selected_char - 1] + word[selected_char] + word[selected_char - 1] + word[selected_char + 1:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 316,
      "metadata": {},
      "outputs": [],
      "source": [
        "def random_replace(word: str) -> str:\n",
        "    \"\"\"\n",
        "    Randomly replace one character with random letter in the given word.\n",
        "    \"\"\"\n",
        "\n",
        "    if len(word) <= 1:\n",
        "        selected_char = 0\n",
        "    else:\n",
        "        selected_char = random.randint(0, len(word) - 1)\n",
        "    letters = 'abcdefghijklmnopqrstuvwxyz'\n",
        "\n",
        "    return word[:selected_char] + random.choice(letters) + word[selected_char + 1:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 317,
      "metadata": {},
      "outputs": [],
      "source": [
        "def random_insert(word: str) -> str:\n",
        "    \"\"\"\n",
        "    Randomly insert one character with random letter in the given word.\n",
        "    \"\"\"\n",
        "\n",
        "    if len(word) <= 1:\n",
        "        selected_char = 0\n",
        "    else:\n",
        "        selected_char = random.randint(0, len(word) - 1)\n",
        "    letters = 'abcdefghijklmnopqrstuvwxyz'\n",
        "\n",
        "    return word[:selected_char] + random.choice(letters) + word[selected_char:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 318,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'happfy'"
            ]
          },
          "execution_count": 318,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "random_insert('happy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 319,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'haupy'"
            ]
          },
          "execution_count": 319,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "random_replace('happy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 320,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'hapyp'"
            ]
          },
          "execution_count": 320,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "random_transpose('happy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 321,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'hapy'"
            ]
          },
          "execution_count": 321,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "random_delete('happy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 322,
      "metadata": {},
      "outputs": [],
      "source": [
        "def random_modification(word: str) -> str:\n",
        "    \"\"\"\n",
        "    Make one or two random modifications for a word.\n",
        "    \"\"\"\n",
        "\n",
        "    modifications = {\n",
        "        0: lambda x: random_insert(x),\n",
        "        1: lambda x: random_replace(x),\n",
        "        2: lambda x: random_transpose(x),\n",
        "        3: lambda x: random_delete(x),\n",
        "    }\n",
        "\n",
        "    modifications_count = random.randint(1, 2)\n",
        "\n",
        "    if modifications_count == 2:\n",
        "        return modifications.get(random.randint(0, 3))(modifications.get(random.randint(0, 3))(word))\n",
        "    else:\n",
        "        return modifications.get(random.randint(0, 3))(word)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 323,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'happy'"
            ]
          },
          "execution_count": 323,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "random_modification('happy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def modify_list(word_list: list[str]) -> list[str]:\n",
        "    \"\"\"\n",
        "    Modify one word from given list of words.\n",
        "    \"\"\"\n",
        "\n",
        "    assert(len(word_list) == 5), (\n",
        "        \"The length of given `word_list` must equal to 5.\"\n",
        "    )\n",
        "\n",
        "    chosen_word_idx = 2\n",
        "\n",
        "    if len(word_list[1]) < 3 and len(word_list[2]) < 3 and len(word_list[3]) < 3:\n",
        "        return word_list\n",
        "    \n",
        "    modified_word = random_modification(word_list[chosen_word_idx])\n",
        "    \n",
        "    return (word_list[:chosen_word_idx] + [modified_word] + word_list[chosen_word_idx + 1:], chosen_word_idx, word_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 326,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(['will', 'have', 'simnificant', 'effects', 'on'],\n",
              " 2,\n",
              " ['will', 'have', 'significant', 'effects', 'on'])"
            ]
          },
          "execution_count": 326,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "modify_list(['will', 'have', 'significant', 'effects', 'on'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate validation set using created functions\n",
        "def generate_modified_set(sent_list: list[list[str]]) -> None:\n",
        "    \"\"\"\n",
        "    Generate the modified lists of given sentences.\n",
        "    \"\"\"\n",
        "\n",
        "    modified_sentences = []\n",
        "    modified_word_idxs = []\n",
        "\n",
        "    for sent in sent_list:\n",
        "        res = modify_list(sent)\n",
        "        modified_sentences.append(res[0])\n",
        "        modified_word_idxs.append(res[1])\n",
        "    \n",
        "    return pd.DataFrame(\n",
        "        data={\n",
        "            \"modified_sentence\": modified_sentences,\n",
        "            \"modified_word_idxs\": modified_word_idxs\n",
        "        }\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 328,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[['that', 'might', 'be', 'interpreted', 'as'],\n",
              " ['made', 'a', 'lot', 'of', 'sacrifices'],\n",
              " ['plant', 'biological', 'and', 'molecular', 'processes'],\n",
              " ['no', 'reason', 'why', 'they', 'should'],\n",
              " ['and', 'he', 'told', 'her', 'he'],\n",
              " ['out', 'of', 'the', 'sight', 'of'],\n",
              " ['i', 'knew', 'how', 'to', 'work'],\n",
              " ['up', 'out', 'of', 'the', 'mud'],\n",
              " ['then', 'he', 'is', 'going', 'to'],\n",
              " ['of', 'the', 'small', 'sample', 'size'],\n",
              " ['deal', 'with', 'them', 'in', 'a'],\n",
              " ['do', \"n't\", 'quite', 'understand', 'the'],\n",
              " ['that', 'it', 'was', 'a', 'simple'],\n",
              " ['the', 'one', 'who', 'had', 'to'],\n",
              " ['of', 'the', 'underlying', 'causes', 'of'],\n",
              " ['to', 'do', 'is', 'to', 'write'],\n",
              " ['i', 'consider', 'them', 'to', 'be'],\n",
              " ['volume', 'and', 'complexity', 'of', 'the'],\n",
              " ['now', 'we', 'are', 'on', 'the'],\n",
              " ['about', 'the', 'long-term', 'health', 'of'],\n",
              " ['that', 'seems', 'to', 'be', 'most'],\n",
              " ['i', 'had', 'never', 'seen', 'her'],\n",
              " ['had', 'served', 'him', 'so', 'well'],\n",
              " ['that', 'they', 'will', 'be', 'successful'],\n",
              " ['with', 'their', 'names', 'on', 'it'],\n",
              " ['the', 'cost', 'and', 'availability', 'of'],\n",
              " ['those', 'of', 'us', 'who', 'just'],\n",
              " ['the', 'question', 'is', 'why', 'is'],\n",
              " ['the', 'next', 'prime', 'minister', 'of'],\n",
              " ['her', 'head', 'to', 'look', 'up'],\n",
              " ['thank', 'you', 'for', 'helping', 'us'],\n",
              " ['have', 'any', 'information', 'on', 'this'],\n",
              " ['may', 'be', 'just', 'a', 'few'],\n",
              " ['be', 'a', 'great', 'place', 'to'],\n",
              " ['to', 'be', 'gained', 'from', 'this'],\n",
              " ['at', 'the', 'forefront', 'of', 'our'],\n",
              " ['the', 'ninth', 'anniversary', 'of', 'the'],\n",
              " ['there', 'are', 'other', 'things', 'you'],\n",
              " ['of', 'public', 'health', 'in', 'houston'],\n",
              " ['what', 'do', 'i', 'look', 'like'],\n",
              " ['of', 'the', 'british', 'and', 'american'],\n",
              " ['stands', 'a', 'better', 'chance', 'of'],\n",
              " ['that', 'is', 'the', 'first', 'of'],\n",
              " ['she', 'told', 'me', 'to', 'take'],\n",
              " ['you', 'do', \"n't\", 'get', 'something'],\n",
              " ['in', 'the', 'foster', 'care', 'and'],\n",
              " ['to', 'grow', 'up', 'and', 'be'],\n",
              " ['as', 'much', 'as', 'they', 'were'],\n",
              " ['along', 'the', 'main', 'street', 'of'],\n",
              " ['the', 'founding', 'fathers', 'of', 'this'],\n",
              " ['ca', \"n't\", 'see', 'that', 'the'],\n",
              " [\"n't\", 'understand', 'how', 'a', 'man'],\n",
              " ['just', 'the', 'way', 'they', 'were'],\n",
              " ['and', 'i', 'could', \"n't\", 'speak'],\n",
              " ['peeking', 'out', 'from', 'under', 'the'],\n",
              " ['was', 'used', 'as', 'a', 'control'],\n",
              " ['trying', 'to', 'get', 'across', 'the'],\n",
              " ['going', 'to', 'our', 'web', 'site'],\n",
              " ['were', 'willing', 'to', 'go', 'along'],\n",
              " ['the', 'rest', 'of', 'the', 'cash'],\n",
              " ['combination', 'of', 'two', 'or', 'more'],\n",
              " ['were', 'just', 'about', 'to', 'go'],\n",
              " ['trying', 'to', 'work', 'with', 'them'],\n",
              " ['he', 'takes', 'issue', 'with', 'the'],\n",
              " ['what', 'would', 'i', 'have', 'done'],\n",
              " ['at', 'the', 'same', 'time', 'he'],\n",
              " ['are', 'we', 'going', 'to', 'learn'],\n",
              " ['to', 'provide', 'an', 'overview', 'of'],\n",
              " ['variance', 'in', 'depression', 'and', 'self-esteem'],\n",
              " ['of', 'the', 'latest', 'and', 'greatest'],\n",
              " ['cost', 'of', 'the', 'program', 'is'],\n",
              " ['lot', 'of', 'people', 'are', 'curious'],\n",
              " ['had', \"n't\", 'realized', 'she', 'was'],\n",
              " ['has', 'been', 'under', 'siege', 'for'],\n",
              " ['wo', \"n't\", 'be', 'intimidated', 'by'],\n",
              " ['feet', 'of', 'office/warehouse', 'space', 'at'],\n",
              " ['of', 'the', 'first', 'page', 'of'],\n",
              " ['information', 'on', 'the', 'girls', 'playoffs'],\n",
              " ['a', 'man', 'in', 'a', 'straw'],\n",
              " ['a', 'little', 'worse', 'for', 'wear'],\n",
              " ['but', 'the', 'old', 'man', 'was'],\n",
              " ['blacks', 'are', 'far', 'more', 'likely'],\n",
              " ['that', 'what', 'you', 'meant', 'to'],\n",
              " ['why', 'could', \"n't\", 'you', 'have'],\n",
              " ['as', 'he', 'rose', 'to', 'his'],\n",
              " ['served', 'on', 'the', 'board', 'of'],\n",
              " ['the', 'heart', 'of', 'the', 'entire'],\n",
              " ['a', 'little', 'part', 'of', 'me'],\n",
              " ['a', 'bit', 'of', 'a', 'stretch'],\n",
              " ['seat', 'to', 'the', 'highest', 'bidder'],\n",
              " ['its', 'own', 'investigation', 'into', 'the'],\n",
              " ['could', 'no', 'longer', 'live', 'in'],\n",
              " ['a', 'matter', 'of', 'how', 'you'],\n",
              " ['be', 'the', 'hardest', 'thing', 'for'],\n",
              " ['things', 'that', 'can', 'go', 'wrong'],\n",
              " ['the', 'kenny', 'and', 'la', 'voie'],\n",
              " ['a', 'witness', 'for', 'the', 'prosecution'],\n",
              " ['and', 'it', 'is', 'precisely', 'this'],\n",
              " ['access', 'to', 'family', 'planning', 'services'],\n",
              " ['has', 'become', 'the', 'focal', 'point'],\n",
              " ['the', 'death', 'of', 'princess', 'diana'],\n",
              " ['have', 'time', 'to', 'look', 'at'],\n",
              " ['what', 'i', 'said', 'in', 'my'],\n",
              " ['sex', 'without', 'a', 'condom', 'after'],\n",
              " ['when', 'did', 'you', 'know', 'you'],\n",
              " ['but', 'it', 'was', 'also', 'true'],\n",
              " ['the', 'use', 'of', 'the', 'title'],\n",
              " ['within', 'a', 'certain', 'time', 'period'],\n",
              " ['for', 'the', 'last', 'four', 'and'],\n",
              " ['be', 'the', 'place', 'where', 'the'],\n",
              " ['think', 'it', 'was', 'important', 'to'],\n",
              " ['of', 'the', 'applicability', 'of', 'the'],\n",
              " ['do', \"n't\", 'think', 'he', 'expected'],\n",
              " ['no', 'more', 'than', 'a', 'small'],\n",
              " ['to', 'get', 'on', 'the', 'ice'],\n",
              " ['want', 'to', 'say', 'in', 'the'],\n",
              " ['but', 'it', 'allowed', 'me', 'to'],\n",
              " ['for', 'that', 'reason', 'i', 'think'],\n",
              " ['the', 'computer', 'as', 'a', 'tool'],\n",
              " ['has', 'declared', 'a', 'state', 'of'],\n",
              " ['final', 'game', 'of', 'the', 'series'],\n",
              " ['up', 'every', 'day', 'and', 'you'],\n",
              " ['hundreds', 'of', 'miles', 'away', 'to'],\n",
              " ['of', 'the', 'reason', 'why', 'the'],\n",
              " ['while', 'the', 'united', 'states', 'was'],\n",
              " ['the', 'realization', 'that', 'they', 'were'],\n",
              " ['from', 'one', 'of', 'his', 'old'],\n",
              " ['into', 'the', 'center', 'of', 'town'],\n",
              " ['are', 'you', 'one', 'of', 'them'],\n",
              " ['that', 'kind', 'of', 'attention', 'to'],\n",
              " [\"n't\", 'want', 'to', 'name', 'names'],\n",
              " ['if', 'he', 'ca', \"n't\", 'keep'],\n",
              " ['headlines', 'from', 'some', 'of', 'the'],\n",
              " ['of', 'state', 'and', 'the', 'secretary'],\n",
              " ['to', 'go', 'to', 'sleep', 'at'],\n",
              " ['do', 'something', 'that', 'no', 'one'],\n",
              " ['this', 'hour', 'of', 'talk', 'of'],\n",
              " ['i', 'wondered', 'if', 'you', 'were'],\n",
              " ['my', 'family', 'is', 'going', 'to'],\n",
              " ['has', 'been', 'named', 'chief', 'of'],\n",
              " ['have', \"n't\", 'seen', 'anything', 'like'],\n",
              " ['not', 'be', 'eligible', 'for', 'the'],\n",
              " ['heat', 'and', 'simmer', 'for', 'about'],\n",
              " ['that', 'we', 'do', \"n't\", 'use'],\n",
              " ['has', 'been', 'making', 'a', 'lot'],\n",
              " ['elements', 'of', 'the', 'dominant', 'culture'],\n",
              " ['the', 'minutiae', 'of', 'daily', 'life'],\n",
              " ['he', 'had', 'not', 'planned', 'to'],\n",
              " ['a', 'woman', 'who', 'came', 'in'],\n",
              " ['torn', 'tendon', 'in', 'his', 'right'],\n",
              " ['to', 'know', 'what', 'has', 'happened'],\n",
              " ['the', 'second', 'of', 'a', 'two-part'],\n",
              " ['that', 'most', 'of', 'those', 'people'],\n",
              " ['and', 'none', 'of', 'us', 'are'],\n",
              " ['problem', 'seems', 'to', 'be', 'that'],\n",
              " ['he', 'did', 'it', 'for', 'the'],\n",
              " ['it', 'clear', 'that', 'i', 'am'],\n",
              " ['in', 'a', 'suicide', 'bombing', 'in'],\n",
              " ['but', 'i', 'seem', 'to', 'be'],\n",
              " ['from', 'his', 'perch', 'on', 'the'],\n",
              " ['it', 'might', 'not', 'be', 'an'],\n",
              " ['the', 'south', 'of', 'market', 'area'],\n",
              " ['also', 'tend', 'to', 'be', 'less'],\n",
              " ['cost', 'of', 'health', 'insurance', 'and'],\n",
              " ['to', 'make', 'a', 'leap', 'of'],\n",
              " ['please', 'send', 'it', 'to', 'commuter'],\n",
              " ['up', 'the', 'path', 'toward', 'the'],\n",
              " ['the', 'florida', 'supreme', 'court', 'yesterday'],\n",
              " ['he', 'has', \"n't\", 'changed', 'at'],\n",
              " ['she', 'told', 'him', 'in', 'a'],\n",
              " ['your', 'way', 'up', 'to', 'the'],\n",
              " ['a', 'tiny', 'slice', 'of', 'the'],\n",
              " ['the', 'best', 'way', 'to', 'save'],\n",
              " ['serve', 'as', 'an', 'introduction', 'to'],\n",
              " ['because', 'i', 'was', 'brought', 'up'],\n",
              " ['as', 'she', 'moves', 'to', 'the'],\n",
              " ['money', 'to', 'pay', 'for', 'these'],\n",
              " ['do', \"n't\", 'get', 'out', 'and'],\n",
              " ['is', 'my', 'belief', 'that', 'the'],\n",
              " ['when', 'you', 'can', 'get', 'a'],\n",
              " ['at', 'the', 'side', 'of', 'her'],\n",
              " ['and', 'scare', 'the', 'hell', 'out'],\n",
              " ['have', 'to', 'compete', 'with', 'other'],\n",
              " ['playing', 'an', 'increasingly', 'important', 'role'],\n",
              " ['and', 'nail', 'them', 'in', 'place'],\n",
              " ['the', 'weeks', 'and', 'months', 'ahead'],\n",
              " ['in', 'their', 'own', 'classrooms', 'and'],\n",
              " ['then', 'turns', 'to', 'look', 'at'],\n",
              " ['that', 'we', 'just', 'heard', 'from'],\n",
              " ['ended', 'up', 'in', 'the', 'hands'],\n",
              " ['on', 'permanent', 'loan', 'to', 'the'],\n",
              " ['and', 'have', 'a', 'great', 'deal'],\n",
              " ['she', 'and', 'her', 'best', 'friend'],\n",
              " ['can', 'predict', 'what', 'will', 'happen'],\n",
              " ['issued', 'a', 'warrant', 'for', 'the'],\n",
              " ['to', 'be', 'a', 'woman', 'in'],\n",
              " ['but', 'she', 'did', \"n't\", 'really'],\n",
              " ['the', 'difference', 'between', 'profit', 'and'],\n",
              " ['has', 'been', 'one', 'of', 'his'],\n",
              " ['really', 'come', 'a', 'long', 'way'],\n",
              " ['refused', 'to', 'allow', 'them', 'to'],\n",
              " ['do', 'the', 'same', 'thing', 'at'],\n",
              " ['may', 'have', 'a', 'role', 'in'],\n",
              " ['many', 'people', 'bothering', 'her', 'all'],\n",
              " ['elected', 'president', 'of', 'the', 'national'],\n",
              " ['and', 'the', 'law', 'of', 'the'],\n",
              " ['showed', 'up', 'at', 'my', 'door'],\n",
              " ['they', 'needed', 'to', 'do', 'to'],\n",
              " ['the', 'door', 'and', 'across', 'the'],\n",
              " ['so', 'i', 'look', 'at', 'this'],\n",
              " ['a', 'pattern', 'similar', 'to', 'the'],\n",
              " ['ways', 'to', 'do', 'it', 'is'],\n",
              " ['the', 'last', 'thing', 'you', 'said'],\n",
              " ['it', 'was', 'in', 'the', 'south'],\n",
              " ['coffee', 'and', 'a', 'piece', 'of'],\n",
              " ['it', 'is', 'interesting', 'to', 'observe'],\n",
              " ['investigation', 'of', 'claims', 'of', 'the'],\n",
              " ['my', 'hand', 'away', 'from', 'the'],\n",
              " ['looked', 'around', 'to', 'make', 'sure'],\n",
              " ['that', 'it', 'seems', 'to', 'be'],\n",
              " ['early', 'in', 'the', 'first', 'quarter'],\n",
              " ['that', 'maybe', 'you', 'did', \"n't\"],\n",
              " ['the', 'middle', 'of', 'the', 'sidewalk'],\n",
              " ['to', 'communicate', 'with', 'the', 'other'],\n",
              " ['took', 'it', 'upon', 'herself', 'to'],\n",
              " ['in', 'the', 'u.s', 'and', 'britain'],\n",
              " ['the', 'best', 'chance', 'we', 'have'],\n",
              " ['in', 'such', 'a', 'long', 'time'],\n",
              " ['were', 'very', 'similar', 'to', 'those'],\n",
              " ['know', 'exactly', 'who', 'he', 'is'],\n",
              " ['and', 'so', 'it', 'was', \"n't\"],\n",
              " ['the', 'look', 'he', 'gave', 'her'],\n",
              " ['i', 'used', 'to', 'go', 'in'],\n",
              " ['for', 'the', 'tasks', 'at', 'hand'],\n",
              " ['at', 'the', 'end', 'of', 'the'],\n",
              " ['understanding', 'what', 'it', 'means', 'to'],\n",
              " ['is', 'a', 'piece', 'of', 'crap'],\n",
              " ['and', 'the', 'government', 'has', 'been'],\n",
              " ['he', 'was', 'taking', 'on', 'the'],\n",
              " ['a', 'crime', 'has', 'been', 'committed'],\n",
              " ['so', 'far', 'as', 'to', 'deny'],\n",
              " ['but', 'he', 'went', 'back', 'to'],\n",
              " ['problems', 'that', 'we', 'have', 'in'],\n",
              " ['come', 'back', 'and', 'talk', 'about'],\n",
              " ['she', 'lost', 'herself', 'in', 'the'],\n",
              " ['so', 'this', 'is', 'kind', 'of'],\n",
              " ['but', 'i', 'was', 'afraid', 'of'],\n",
              " ['he', 'thought', 'long', 'and', 'hard'],\n",
              " ['told', 'you', 'i', 'ca', \"n't\"],\n",
              " ['children', 'in', 'the', 'foster', 'care'],\n",
              " ['and', 'for', 'me', 'it', 'was'],\n",
              " ['her', 'side', 'of', 'the', 'bed'],\n",
              " ['is', 'the', 'only', 'way', 'i'],\n",
              " ['going', 'to', 'go', 'do', 'that'],\n",
              " ['it', 'failed', 'to', 'do', 'so'],\n",
              " ['the', 'other', 'half', 'is', 'the'],\n",
              " ['was', 'sitting', 'on', 'the', 'porch'],\n",
              " ['it', 'was', 'not', 'always', 'so'],\n",
              " ['and', 'found', 'himself', 'in', 'a'],\n",
              " ['services', 'in', 'the', 'united', 'states'],\n",
              " ['at', 'the', 'same', 'time', 'just'],\n",
              " ['everyone', 'else', 'is', 'doing', 'it'],\n",
              " ['and', 'it', 'was', 'time', 'to'],\n",
              " ['at', 'his', 'home', 'in', 'los'],\n",
              " ['efforts', 'to', 'crack', 'down', 'on'],\n",
              " ['on', 'alcohol', 'and', 'drug', 'abuse'],\n",
              " ['do', \"n't\", 'get', 'mad', 'at'],\n",
              " ['that', 'i', 'was', 'making', 'a'],\n",
              " ['signed', 'a', 'new', 'deal', 'with'],\n",
              " ['that', 'she', 'wants', 'to', 'get'],\n",
              " ['done', 'a', 'good', 'job', 'in'],\n",
              " ['no', 'evidence', 'that', 'she', 'was'],\n",
              " ['found', 'that', 'people', 'with', 'a'],\n",
              " ['in', 'a', 'recent', 'poll', 'by'],\n",
              " ['the', 'rear', 'of', 'the', 'ship'],\n",
              " ['government', 'does', 'not', 'have', 'to'],\n",
              " ['the', 'environment', 'in', 'which', 'these'],\n",
              " ['for', 'me', 'is', 'that', 'i'],\n",
              " ['that', 'was', 'what', 'we', 'were'],\n",
              " ['thing', 'is', 'going', 'to', 'happen'],\n",
              " ['he', 'needed', 'was', 'to', 'get'],\n",
              " ['i', 'did', \"n't\", 'steal', 'anything'],\n",
              " ['passion', 'of', 'the', 'western', 'mind'],\n",
              " ['did', \"n't\", 'hear', 'anything', 'more'],\n",
              " ['we', 'now', 'have', 'a', 'president'],\n",
              " ['i', 'think', 'she', 'was', 'in'],\n",
              " ['at', 'the', 'expense', 'of', 'economic'],\n",
              " ['the', 'end', 'it', 'was', 'the'],\n",
              " ['you', 'know', 'that', 'you', 'had'],\n",
              " ['tell', 'her', 'what', 'he', 'had'],\n",
              " ['it', 'can', 'take', 'an', 'hour'],\n",
              " ['between', 'the', 'government', 'and', 'the'],\n",
              " ['going', 'to', 'see', 'a', 'big'],\n",
              " ['will', 'have', 'to', 'be', 'there'],\n",
              " ['stairs', 'leading', 'down', 'to', 'the'],\n",
              " ['who', 'happened', 'to', 'be', 'passing'],\n",
              " ['been', 'in', 'the', 'soviet', 'union'],\n",
              " ['have', 'good', 'reason', 'to', 'think'],\n",
              " ['there', 'seem', 'to', 'be', 'few'],\n",
              " ['is', 'a', 'compromise', 'between', 'the'],\n",
              " ['i', 'had', 'the', 'misfortune', 'of'],\n",
              " ['did', \"n't\", 'understand', 'how', 'it'],\n",
              " ['and', 'then', 'closed', 'the', 'door'],\n",
              " ['put', 'a', 'finger', 'on', 'it'],\n",
              " ['on', 'the', 'floor', 'and', 'he'],\n",
              " ['the', 'number', 'of', 'americans', 'with'],\n",
              " ['issues', 'that', 'relate', 'to', 'the'],\n",
              " ['to', 'establish', 'some', 'sort', 'of'],\n",
              " ['up', 'and', 'down', 'on', 'a'],\n",
              " ['want', 'you', 'to', 'come', 'and'],\n",
              " ['be', 'including', 'your', 'phone', 'calls'],\n",
              " ['to', 'give', 'her', 'last', 'name'],\n",
              " ['just', 'stood', 'there', 'with', 'his'],\n",
              " ['the', 'last', 'time', 'he', 'spoke'],\n",
              " ['he', 'gets', 'up', 'in', 'the'],\n",
              " ['in', 'the', 'health', 'care', 'delivery'],\n",
              " ['it', 'is', 'a', 'process', 'that'],\n",
              " ['would', 'not', 'have', 'been', 'as'],\n",
              " ['if', 'she', 'were', 'on', 'the'],\n",
              " ['final', 'week', 'of', 'the', 'regular'],\n",
              " ['i', 'could', 'not', 'remember', 'what'],\n",
              " ['has', 'one', 'of', 'the', 'more'],\n",
              " ['from', 'a', 'review', 'of', 'the'],\n",
              " ['this', 'is', 'the', 'focus', 'of'],\n",
              " ['three', 'themes', 'emerged', 'from', 'the'],\n",
              " ['beginning', 'of', 'a', 'new', 'century'],\n",
              " ['those', 'who', 'violate', 'the', 'law'],\n",
              " ['taking', 'a', 'hard', 'look', 'at'],\n",
              " ['we', 'can', 'not', 'escape', 'the'],\n",
              " ['gunshot', 'wound', 'to', 'the', 'chest'],\n",
              " ['back', 'of', 'the', 'bus', 'and'],\n",
              " ['you', 'are', 'under', 'arrest', 'for'],\n",
              " ['not', 'in', 'any', 'position', 'to'],\n",
              " ['forth', 'in', 'front', 'of', 'her'],\n",
              " ['anyone', 'else', 'in', 'my', 'family'],\n",
              " ['for', 'hundreds', 'of', 'miles', 'around'],\n",
              " ['the', 'internet', 'is', 'a', 'great'],\n",
              " ['wanted', 'to', 'meet', 'with', 'the'],\n",
              " ['sounded', 'like', 'he', 'was', 'in'],\n",
              " ['and', 'this', 'is', 'where', 'you'],\n",
              " ['that', 'was', 'what', 'they', 'said'],\n",
              " ['as', 'the', 'spirit', 'of', 'the'],\n",
              " ['life', 'in', 'the', 'united', 'states'],\n",
              " ['the', 'genetics', 'and', 'public', 'policy'],\n",
              " ['in', 'the', 'chair', 'by', 'the'],\n",
              " ['it', 'to', 'the', 'status', 'of'],\n",
              " ['to', 'a', 'whole', 'host', 'of'],\n",
              " ['noting', 'that', 'many', 'of', 'the'],\n",
              " ['the', 'u.s', 'military', 'effort', 'in'],\n",
              " ['involved', 'in', 'the', 'arts', 'and'],\n",
              " ['he', 'was', 'asked', 'if', 'the'],\n",
              " ['started', 'to', 'show', 'signs', 'of'],\n",
              " ['and', 'that', 'was', 'all', 'it'],\n",
              " ['a', 'leader', 'of', 'the', 'free'],\n",
              " ['was', 'scheduled', 'to', 'be', 'in'],\n",
              " ['he', 'was', 'last', 'seen', 'by'],\n",
              " ['if', 'this', 'analysis', 'is', 'correct'],\n",
              " ['and', 'it', 'is', 'not', 'my'],\n",
              " ['in', 'an', 'interview', 'last', 'month'],\n",
              " [\"n't\", 'need', 'a', 'lawyer', 'to'],\n",
              " ['think', 'one', 'of', 'the', 'best'],\n",
              " ['an', 'opportunity', 'to', 'do', 'it'],\n",
              " ['to', 'the', 'knowledge', 'of', 'the'],\n",
              " ['survived', 'an', 'assassination', 'attempt', 'in'],\n",
              " [\"n't\", 'have', 'a', 'clue', 'as'],\n",
              " ['in', 'the', 'colonial', 'revival', 'style'],\n",
              " ['had', 'given', 'up', 'on', 'the'],\n",
              " ['and', 'i', 'went', 'into', 'my'],\n",
              " ['that', 'it', 'was', 'like', 'a'],\n",
              " ['that', 'could', 'compete', 'with', 'the'],\n",
              " ['foundation', 'for', 'the', 'defense', 'of'],\n",
              " ['from', 'the', 'use', 'of', 'the'],\n",
              " ['at', 'their', 'home', 'in', 'the'],\n",
              " ['or', 'in', 'new', 'york', 'or'],\n",
              " ['are', 'back', 'once', 'again', 'with'],\n",
              " ['like', 'we', 'did', \"n't\", 'have'],\n",
              " ['in', 'the', 'presence', 'of', 'some'],\n",
              " ['is', 'the', 'start', 'of', 'the'],\n",
              " ['the', 'alameda', 'naval', 'air', 'station'],\n",
              " ['they', 'want', 'to', 'find', 'a'],\n",
              " ['sky', 'at', 'times', 'shown', 'in'],\n",
              " ['also', 'use', 'it', 'as', 'a'],\n",
              " ['the', 'main', 'effects', 'of', 'the'],\n",
              " ['clear', 'to', 'me', 'that', 'he'],\n",
              " ['chairman', 'of', 'the', 'task', 'force'],\n",
              " ['percent', 'of', 'children', 'with', 'disabilities'],\n",
              " ['i', 'should', 'have', 'known', 'he'],\n",
              " ['room', 'is', 'now', 'filled', 'with'],\n",
              " ['i', 'think', 'for', 'me', 'it'],\n",
              " ['nation', 'of', 'islam', 'leader', 'louis'],\n",
              " ['the', 'closing', 'down', 'of', 'the'],\n",
              " ['consistent', 'with', 'the', 'spirit', 'of'],\n",
              " ['going', 'to', 'be', 'seeing', 'more'],\n",
              " ['are', 'voted', 'on', 'by', 'the'],\n",
              " ['the', 'time', 'we', 'reached', 'the'],\n",
              " ['said', 'i', 'do', \"n't\", 'believe'],\n",
              " ['want', 'to', 'ask', 'you', 'guys'],\n",
              " ['it', 'wo', \"n't\", 'work', 'if'],\n",
              " ['then', 'i', 'said', 'to', 'myself'],\n",
              " ['are', 'more', 'likely', 'to', 'say'],\n",
              " ['of', 'the', 'white', 'house', 'counsel'],\n",
              " ['and', 'asked', 'me', 'why', 'i'],\n",
              " ['of', 'the', 'indigenous', 'population', 'of'],\n",
              " ['who', 'do', 'not', 'share', 'our'],\n",
              " ['they', 'really', 'do', \"n't\", 'understand'],\n",
              " ['as', 'long', 'as', 'interest', 'rates'],\n",
              " ['two', 'and', 'a', 'half', 'minutes'],\n",
              " ['the', 'top', 'of', 'the', 'slope'],\n",
              " ['up', 'without', 'a', 'lot', 'of'],\n",
              " ['grew', 'up', 'in', 'san', 'jose'],\n",
              " ['look', 'at', 'this', 'one', 'here'],\n",
              " ['did', 'not', 'try', 'to', 'kill'],\n",
              " ['accept', 'your', 'nomination', 'for', 'president'],\n",
              " ['is', 'stretched', 'out', 'on', 'a'],\n",
              " ['the', 'rest', 'of', 'the', 'papers'],\n",
              " ['to', 'learn', 'that', 'in', 'the'],\n",
              " ['there', 'was', 'a', 'chance', 'for'],\n",
              " ['was', 'going', 'to', 'work', 'out'],\n",
              " ['be', 'in', 'the', 'front', 'of'],\n",
              " ['at', 'the', 'age', 'of', 'seventy-five'],\n",
              " ['it', 'was', 'typical', 'of', 'the'],\n",
              " ['to', 'be', 'installed', 'in', 'the'],\n",
              " ['growing', 'up', 'out', 'of', 'the'],\n",
              " ['mother', 'of', 'two', 'teenage', 'boys'],\n",
              " ['earned', 'the', 'right', 'to', 'be'],\n",
              " ['but', 'new', 'research', 'suggests', 'that'],\n",
              " ['the', 'old', 'executive', 'office', 'building'],\n",
              " ['get', 'the', 'money', 'to', 'build'],\n",
              " ['is', 'the', 'ultimate', 'arbiter', 'of'],\n",
              " ['it', 'was', 'something', 'he', 'did'],\n",
              " ['to', 'step', 'on', 'the', 'scale'],\n",
              " ['that', 'does', \"n't\", 'make', 'sense'],\n",
              " ['find', 'a', 'peaceful', 'solution', 'to'],\n",
              " ['would', 'have', 'wanted', 'to', 'know'],\n",
              " ['and', 'even', 'if', 'you', 'are'],\n",
              " ['actually', 'do', 'more', 'harm', 'than'],\n",
              " ['be', 'an', 'easy', 'way', 'to'],\n",
              " ['i', 'wanted', 'to', 'go', 'with'],\n",
              " ['a', 'private', 'audience', 'with', 'the'],\n",
              " ['to', 'go', 'back', 'and', 'listen'],\n",
              " ['you', 'let', 'them', 'know', 'that'],\n",
              " ['at', 'the', 'flip', 'of', 'a'],\n",
              " ['got', 'what', 'it', 'takes', 'to'],\n",
              " ['is', 'the', 'second', 'of', 'two'],\n",
              " ['at', 'it', 'for', 'a', 'while'],\n",
              " ['hard', 'as', 'i', 'could', 'to'],\n",
              " ['think', 'should', 'be', 'featured', 'in'],\n",
              " ['whether', 'or', 'not', 'it', 'meets'],\n",
              " ['they', 'said', 'he', 'was', \"n't\"],\n",
              " ['away', 'from', 'the', 'others', 'and'],\n",
              " ['did', \"n't\", 'come', 'to', 'pass'],\n",
              " ['we', 'try', 'to', 'make', 'the'],\n",
              " ['played', 'a', 'central', 'role', 'in'],\n",
              " ['we', 'can', 'do', 'business', 'with'],\n",
              " ['a', 'good', 'thing', 'when', 'he'],\n",
              " ['an', 'unintended', 'consequence', 'of', 'this'],\n",
              " ['and', 'in', 'a', 'time', 'when'],\n",
              " ['he', 'was', 'no', 'longer', 'the'],\n",
              " ['obviously', 'we', 'do', \"n't\", 'know'],\n",
              " ['really', 'have', 'anything', 'to', 'say'],\n",
              " ['as', 'he', 'was', 'coming', 'out'],\n",
              " ['we', 'do', \"n't\", 'know', 'precisely'],\n",
              " ['they', 'do', \"n't\", 'lose', 'their'],\n",
              " ['the', 'shoulder', 'of', 'the', 'road'],\n",
              " ['us', 'is', 'one', 'of', 'the'],\n",
              " ['an', 'opportunity', 'to', 'develop', 'a'],\n",
              " ['than', 'five', 'minutes', 'in', 'the'],\n",
              " ['good', 'people', 'trying', 'to', 'do'],\n",
              " ['the', 'rest', 'of', 'this', 'decade'],\n",
              " ['that', 'from', 'the', 'bottom', 'of'],\n",
              " ['in', 'the', 'planning', 'for', 'the'],\n",
              " ['feet', 'up', 'on', 'the', 'desk'],\n",
              " ['i', 'did', \"n't\", 'even', 'meet'],\n",
              " ['you', 'expect', 'us', 'to', 'do'],\n",
              " ['from', 'the', 'back', 'door', 'of'],\n",
              " ['what', 'happened', 'a', 'few', 'days'],\n",
              " ['are', 'under', 'tremendous', 'pressure', 'to'],\n",
              " ['see', 'if', 'we', 'can', 'take'],\n",
              " ['problems', 'that', 'are', 'associated', 'with'],\n",
              " ['at', 'the', 'time', 'he', 'said'],\n",
              " ['percent', 'over', 'the', 'next', 'five'],\n",
              " ['to', 'be', 'in', 'an', 'area'],\n",
              " ['now', 'on', 'the', 'brink', 'of'],\n",
              " ['she', 'was', 'one', 'of', 'a'],\n",
              " ['to', 'win', 'in', 'order', 'to'],\n",
              " [\"n't\", 'need', 'to', 'be', 'asked'],\n",
              " ['important', 'for', 'people', 'to', 'know'],\n",
              " ['i', 'remember', 'we', 'used', 'to'],\n",
              " ['of', 'power', 'between', 'the', 'states'],\n",
              " ['going', 'to', 'say', 'it', 'again'],\n",
              " ['up', 'in', 'the', 'same', 'home'],\n",
              " ['the', 'same', 'thing', 'i', 'was'],\n",
              " ['she', 'saw', 'him', 'at', 'the'],\n",
              " ['one', 'of', 'the', 'four', 'of'],\n",
              " ['of', 'the', 'kind', 'found', 'in'],\n",
              " ['in', 'the', 'process', 'of', 'refining'],\n",
              " ['would', 'be', 'easier', 'to', 'understand'],\n",
              " ['a', 'member', 'of', 'our', 'family'],\n",
              " ['it', 'was', 'a', 'gesture', 'that'],\n",
              " ['three', 'meals', 'a', 'day', 'for'],\n",
              " ['first', 'to', 'point', 'out', 'the'],\n",
              " ['average', 'vertical', 'logged', 'per', 'day'],\n",
              " ['about', 'when', 'we', 'talk', 'about'],\n",
              " [\"n't\", 'expected', 'to', 'be', 'a'],\n",
              " ['the', 'middle', 'of', 'it', 'was'],\n",
              " ['but', 'i', 'thought', 'we', 'were'],\n",
              " ['willing', 'to', 'do', 'that', 'in'],\n",
              " ['at', 'higher', 'risk', 'for', 'heart'],\n",
              " ['it', 'was', 'all', 'a', 'hoax'],\n",
              " ['but', 'those', 'are', 'the', 'kinds'],\n",
              " ['put', 'a', 'lot', 'of', 'people'],\n",
              " ['in', 'the', 'past', 'year', 'because'],\n",
              " ['is', 'seen', 'as', 'a', 'part'],\n",
              " ['for', 'some', 'time', 'about', 'the'],\n",
              " ['is', 'what', 'happened', 'with', 'the'],\n",
              " ['of', 'what', 'they', 'say', 'is'],\n",
              " ['who', 'was', 'able', 'to', 'see'],\n",
              " ['the', 'american', 'people', 'when', 'it'],\n",
              " ['part', 'of', 'an', 'attempt', 'to'],\n",
              " ['based', 'on', 'the', 'claim', 'that'],\n",
              " ['to', 'fight', 'and', 'die', 'in'],\n",
              " ['united', 'states', 'with', 'regard', 'to'],\n",
              " ['on', 'a', 'side', 'street', 'in'],\n",
              " ['the', 'sight', 'of', 'so', 'many'],\n",
              " ['as', 'they', 'went', 'down', 'the'],\n",
              " ['face', 'and', 'the', 'back', 'of'],\n",
              " ['him', 'because', 'of', 'what', 'he'],\n",
              " ['my', 'back', 'to', 'the', 'wall'],\n",
              " ['want', 'to', 'get', 'to', 'know'],\n",
              " ['a', 'situation', 'where', 'the', 'president'],\n",
              " [\"n't\", 'you', 'go', 'back', 'to'],\n",
              " ['on', 'the', 'authority', 'of', 'the'],\n",
              " ['had', 'been', 'a', 'bad', 'idea'],\n",
              " ['something', 'you', 'do', \"n't\", 'understand'],\n",
              " ['up', 'at', 'the', 'ceiling', 'as'],\n",
              " ['but', 'also', 'a', 'number', 'of'],\n",
              " ['now', 'coming', 'out', 'of', 'the'],\n",
              " ['just', 'out', 'of', 'the', 'blue'],\n",
              " ['got', 'a', 'little', 'bit', 'older'],\n",
              " ['member', 'of', 'the', 'republican', 'party'],\n",
              " ['based', 'on', 'what', 'he', 'said'],\n",
              " ['into', 'a', 'sense', 'of', 'complacency'],\n",
              " ['tsp', 'freshly', 'ground', 'black', 'pepper'],\n",
              " ['to', 'one', 'of', 'the', 'people'],\n",
              " ['me', 'just', 'as', 'much', 'as'],\n",
              " ['as', 'a', 'leader', 'among', 'the'],\n",
              " ['people', 'see', 'me', 'as', 'a'],\n",
              " ['and', 'if', 'you', 'do', 'something'],\n",
              " ['bit', 'later', 'in', 'this', 'broadcast'],\n",
              " ['was', 'exactly', 'what', 'she', 'was'],\n",
              " ['the', 'rest', 'of', 'the', 'squad'],\n",
              " ['in', 'order', 'to', 'get', 'an'],\n",
              " ['that', 'there', 'may', 'indeed', 'be'],\n",
              " ['been', 'a', 'matter', 'of', 'concern'],\n",
              " ['more', 'about', 'what', 'kind', 'of'],\n",
              " ['no', 'longer', 'know', 'what', 'to'],\n",
              " ['that', 'you', 'have', 'to', 'talk'],\n",
              " ['has', 'been', 'the', 'order', 'of'],\n",
              " ['made', 'in', 'the', 'wake', 'of'],\n",
              " ['never', 'get', 'in', 'the', 'way'],\n",
              " ['but', 'i', 'am', 'here', 'to'],\n",
              " ['what', 'i', 'am', 'looking', 'for'],\n",
              " ['said', 'a', 'couple', 'of', 'weeks'],\n",
              " ['seemed', 'to', 'be', 'a', 'little'],\n",
              " ['at', 'least', 'i', 'would', \"n't\"],\n",
              " ['during', 'his', 'first', 'week', 'in'],\n",
              " ['change', 'in', 'the', 'arab', 'world'],\n",
              " ['going', 'back', 'to', 'the', 'days'],\n",
              " ['the', 'holidays', 'are', 'a', 'time'],\n",
              " ['in', 'a', 'straw', 'hat', 'and'],\n",
              " ['want', 'to', 'take', 'it', 'all'],\n",
              " ['secretary', 'of', 'state', 'in', 'a'],\n",
              " ['was', \"n't\", 'anything', 'in', 'the'],\n",
              " ['i', 'intend', 'to', 'keep', 'my'],\n",
              " ['out', 'what', 'we', 'want', 'to'],\n",
              " ['thought', 'you', 'were', \"n't\", 'supposed'],\n",
              " ['saved', 'the', 'life', 'of', 'a'],\n",
              " ['of', 'great', 'britain', 'and', 'ireland'],\n",
              " ['system', 'was', 'based', 'on', 'the'],\n",
              " ['miles', 'northwest', 'of', 'downtown', 'los'],\n",
              " ['stuff', 'that', 'i', 'did', \"n't\"],\n",
              " ['what', 'you', 'were', 'getting', 'at'],\n",
              " ['in', 'a', 'bid', 'to', 'make'],\n",
              " ['to', 'suggest', 'that', 'it', 'might'],\n",
              " ['all', 'the', 'time', 'he', 'spent'],\n",
              " ['how', 'am', 'i', 'gon', 'na'],\n",
              " ['did', \"n't\", 'exist', 'back', 'then'],\n",
              " ['antonio', 'lpez', 'de', 'santa', 'anna'],\n",
              " ['he', 'played', 'the', 'role', 'of'],\n",
              " ['look', 'at', 'the', 'makeup', 'of'],\n",
              " ['and', 'stares', 'down', 'at', 'the'],\n",
              " ['in', 'a', 'blaze', 'of', 'glory'],\n",
              " ['would', 'not', 'give', 'her', 'last'],\n",
              " ['at', 'the', 'moment', 'i', 'was'],\n",
              " ['do', \"n't\", 'want', 'to', 'burn'],\n",
              " ['the', 'plaintiff', 'in', 'the', 'case'],\n",
              " ['on', 'the', 'total', 'amount', 'of'],\n",
              " ['get', 'in', 'the', 'mood', 'for'],\n",
              " ['and', 'lay', 'down', 'on', 'his'],\n",
              " ['this', 'would', 'be', 'one', 'of'],\n",
              " ['on', 'the', 'ride', 'back', 'to'],\n",
              " ['would', 'have', 'to', 'say', 'yes'],\n",
              " ['the', 'form', 'and', 'shape', 'of'],\n",
              " ['in', 'that', 'it', 'can', 'be'],\n",
              " ['great', 'deal', 'in', 'common', 'with'],\n",
              " ['the', 'least', 'bit', 'concerned', 'about'],\n",
              " ['the', 'rates', 'do', 'not', 'include'],\n",
              " ['that', 'are', 'included', 'in', 'the'],\n",
              " ['for', 'the', 'fact', 'that', 'he'],\n",
              " ['unimpaired', 'for', 'the', 'enjoyment', 'of'],\n",
              " ['the', 'chief', 'of', 'staff', 'job'],\n",
              " ['is', 'the', 'idea', 'that', 'this'],\n",
              " ['present', 'one', 'of', 'the', 'most'],\n",
              " ['like', 'his', 'father', 'and', 'his'],\n",
              " ['world', 'player', 'of', 'the', 'year'],\n",
              " ['the', 'exhibition', 'standards', 'director', 'for'],\n",
              " ['that', 'most', 'people', 'could', \"n't\"],\n",
              " ['the', 'fire', 'was', 'deliberately', 'set'],\n",
              " [\"n't\", 'want', 'to', 'hear', 'him'],\n",
              " ['and', 'wanted', 'to', 'know', 'how'],\n",
              " ['is', 'cool', 'enough', 'to', 'handle'],\n",
              " ['to', 'step', 'up', 'and', 'fill'],\n",
              " ['remain', 'a', 'vital', 'part', 'of'],\n",
              " ['will', 'you', 'permit', 'me', 'to'],\n",
              " ['would', \"n't\", 'be', 'the', 'end'],\n",
              " ['they', 'do', \"n't\", 'have', 'to'],\n",
              " ['at', 'this', 'time', 'last', 'year'],\n",
              " ['to', 'change', 'the', 'status', 'quo'],\n",
              " ['there', 'is', 'a', 'connection', 'with'],\n",
              " ['with', 'so', 'much', 'on', 'the'],\n",
              " ['two', 'groups', 'with', 'regard', 'to'],\n",
              " ['he', 'was', 'tall', 'and', 'thin'],\n",
              " ['tried', 'to', 'find', 'out', 'why'],\n",
              " ['shape', 'up', 'or', 'ship', 'out'],\n",
              " ['she', 'pretended', 'not', 'to', 'notice'],\n",
              " ['as', 'he', 'leaned', 'over', 'the'],\n",
              " ['was', 'in', 'the', 'back', 'room'],\n",
              " ['our', 'way', 'out', 'of', 'our'],\n",
              " ['usually', 'do', \"n't\", 'have', 'the'],\n",
              " ['what', 'happened', 'the', 'night', 'of'],\n",
              " ['it', 'just', 'did', \"n't\", 'come'],\n",
              " ['the', 'early', 'phase', 'of', 'the'],\n",
              " ['and', 'i', 'can', 'only', 'imagine'],\n",
              " ['his', 'first', 'tour', 'in', 'iraq'],\n",
              " ['and', 'the', 'voice', 'of', 'the'],\n",
              " ['the', 'way', 'they', 'are', 'now'],\n",
              " ['of', 'the', 'latest', 'crop', 'of'],\n",
              " ['a', 'lot', 'of', 'people', 'angry'],\n",
              " ['now', 'the', 'executive', 'director', 'of'],\n",
              " ['do', \"n't\", 'have', 'a', 'husband'],\n",
              " ['the', 'interesting', 'thing', 'is', 'they'],\n",
              " ['to', 'have', 'a', 'clear', 'idea'],\n",
              " ['state', 'of', 'the', 'union', 'has'],\n",
              " ['have', 'no', 'weapons', 'of', 'mass'],\n",
              " ['had', 'a', 'hand', 'in', 'drafting'],\n",
              " ['was', 'only', 'a', 'couple', 'of'],\n",
              " ['not', 'want', 'to', 'talk', 'to'],\n",
              " ['have', 'any', 'problem', 'with', 'the'],\n",
              " ['looks', 'like', 'some', 'kind', 'of'],\n",
              " ['on', 'the', 'street', 'and', 'it'],\n",
              " ['he', 'could', 'be', 'sent', 'back'],\n",
              " ['is', 'the', 'government', 'of', 'the'],\n",
              " ['in', 'front', 'of', 'television', 'cameras'],\n",
              " ['were', 'you', 'shocked', 'when', 'you'],\n",
              " ['he', 'is', 'accompanied', 'by', 'a'],\n",
              " ['and', 'then', 'he', 'saw', 'me'],\n",
              " ['was', 'a', 'refreshing', 'change', 'from'],\n",
              " ['because', 'it', 'was', 'just', 'too'],\n",
              " ['it', 'really', 'was', \"n't\", 'until'],\n",
              " ['announced', 'his', 'intention', 'to', 'retire'],\n",
              " ['in', 'the', 'face', 'of', 'political'],\n",
              " ['there', 'is', 'enough', 'evidence', 'to'],\n",
              " ['this', 'is', 'the', 'view', 'that'],\n",
              " ['do', 'i', 'have', 'to', 'wear'],\n",
              " ['part', 'of', 'the', 'food', 'chain'],\n",
              " ['used', 'to', 'be', 'that', 'we'],\n",
              " ['the', 'same', 'time', 'it', 'does'],\n",
              " [\"n't\", 'be', 'surprised', 'if', 'a'],\n",
              " ['which', 'is', 'the', 'kind', 'of'],\n",
              " ['there', 'are', 'certainly', 'a', 'lot'],\n",
              " ['not', 'at', 'the', 'risk', 'of'],\n",
              " ['is', 'strong', 'and', 'getting', 'stronger'],\n",
              " ['in', 'order', 'to', 'take', 'over'],\n",
              " ['with', 'the', 'puzzle', 'editor', 'of'],\n",
              " ['do', 'you', 'think', 'maybe', 'you'],\n",
              " [\"n't\", 'need', 'to', 'see', 'that'],\n",
              " ['like', 'i', 'was', 'doing', 'something'],\n",
              " ['and', 'it', 'sounds', 'like', 'it'],\n",
              " ['before', 'he', 'got', 'out', 'of'],\n",
              " ['said', 'that', 'they', 'did', \"n't\"],\n",
              " ['i', 'ca', \"n't\", 'even', 'guess'],\n",
              " ['the', 'top', 'of', 'the', 'tower'],\n",
              " ['no', 'way', 'to', 'make', 'a'],\n",
              " ['you', 'and', 'i', 'will', 'have'],\n",
              " ['what', 'is', 'it', 'supposed', 'to'],\n",
              " ['giving', 'a', 'speech', 'at', 'the'],\n",
              " ['of', 'a', 'much', 'more', 'complex'],\n",
              " ['because', 'we', 'do', \"n't\", 'like'],\n",
              " ['served', 'in', 'the', 'u.s', 'military'],\n",
              " ['a', 'couple', 'of', 'years', 'at'],\n",
              " ['in', 'the', 'woods', 'and', 'the'],\n",
              " ['tears', 'come', 'to', 'my', 'eyes'],\n",
              " ['for', 'a', 'moment', 'and', 'try'],\n",
              " ['would', 'have', 'to', 'go', 'and'],\n",
              " ['to', 'what', 'he', 'does', 'best'],\n",
              " ['he', 'had', 'ever', 'had', 'in'],\n",
              " ['announced', 'that', 'it', 'would', 'consider'],\n",
              " ['would', 'not', 'take', 'long', 'to'],\n",
              " ['results', 'similar', 'to', 'those', 'of'],\n",
              " ['at', 'the', 'industrial', 'college', 'of'],\n",
              " ['bring', 'it', 'to', 'you', 'as'],\n",
              " ['secretary', 'of', 'defense', 'in', 'the'],\n",
              " ['make', 'the', 'kind', 'of', 'changes'],\n",
              " ['have', 'fought', 'three', 'wars', 'since'],\n",
              " ['not', 'seem', 'to', 'be', 'much'],\n",
              " ['in', 'which', 'he', 'kept', 'his'],\n",
              " ['tell', 'me', 'exactly', 'what', 'you'],\n",
              " ['as', 'she', 'got', 'out', 'of'],\n",
              " ['been', 'changed', 'to', 'protect', 'their'],\n",
              " ['and', 'it', 'was', 'in', 'this'],\n",
              " ['since', 'we', 'do', \"n't\", 'know'],\n",
              " [\"n't\", 'had', 'a', 'raise', 'in'],\n",
              " ['want', 'to', 'sit', 'back', 'and'],\n",
              " ['of', 'the', 'miracle', 'of', 'the'],\n",
              " ['would', \"n't\", 'that', 'be', 'nice'],\n",
              " ['time', 'for', 'the', 'defense', 'to'],\n",
              " ['how', 'much', 'i', 'love', 'her'],\n",
              " ['between', 'january', 'and', 'may', 'of'],\n",
              " ['that', 'need', 'to', 'be', 'asked'],\n",
              " ['why', 'did', \"n't\", 'you', 'take'],\n",
              " ['know', 'what', 'had', 'become', 'of'],\n",
              " ['so', 'i', 'think', 'we', 'could'],\n",
              " ['he', 'feels', 'he', 'needs', 'to'],\n",
              " ['and', 'in', 'a', 'way', 'i'],\n",
              " ['than', 'willing', 'to', 'talk', 'about'],\n",
              " ['few', 'years', 'ago', 'he', 'was'],\n",
              " ['are', 'you', 'afraid', 'to', 'die'],\n",
              " ['when', 'he', 'found', 'out', 'the'],\n",
              " ['the', 'public', 'sector', 'and', 'the'],\n",
              " ['is', 'estimated', 'to', 'be', 'worth'],\n",
              " ['did', \"n't\", 'do', 'a', 'whole'],\n",
              " ['at', 'the', 'root', 'of', 'their'],\n",
              " ['more', 'than', 'six', 'years', 'since'],\n",
              " ['what', 'your', 'doctor', 'needs', 'to'],\n",
              " ['a', 'large', 'skillet', 'over', 'medium'],\n",
              " ['that', 'there', 'must', 'be', 'something'],\n",
              " ['do', 'you', 'want', 'to', 'raise'],\n",
              " ['he', 'also', 'said', 'that', 'in'],\n",
              " ['the', 'fact', 'that', 'you', 'came'],\n",
              " ['every', 'minute', 'of', 'every', 'day'],\n",
              " ['is', 'that', 'why', 'you', 'came'],\n",
              " ['the', 'more', 'i', 'want', 'to'],\n",
              " ['more', 'than', 'a', 'decade', 'with'],\n",
              " ['meeting', 'for', 'the', 'first', 'time'],\n",
              " ['the', 'back', 'of', 'the', 'dining'],\n",
              " ['a', 'random', 'telephone', 'survey', 'of'],\n",
              " ['in', 'store', 'for', 'you', 'every'],\n",
              " ['trade', 'as', 'well', 'as', 'the'],\n",
              " ['one', 'can', 'only', 'wonder', 'if'],\n",
              " ['called', 'for', 'the', 'development', 'of'],\n",
              " ['professor', 'of', 'biomedical', 'engineering', 'at'],\n",
              " ['remove', 'remaining', 'sheet', 'of', 'waxed'],\n",
              " ['i', 'think', 'everybody', 'in', 'america'],\n",
              " ['the', 'money', 'is', 'used', 'for'],\n",
              " ['as', 'first', 'lady', 'of', 'arkansas'],\n",
              " ['the', 'bottom', 'line', 'in', 'this'],\n",
              " ['a', 'direct', 'result', 'of', 'a'],\n",
              " ['right', 'to', 'petition', 'the', 'government'],\n",
              " ['i', 'hardly', 'know', 'how', 'to'],\n",
              " ['as', 'a', 'top', 'aide', 'to'],\n",
              " ['programs', 'like', 'medicare', 'and', 'medicaid'],\n",
              " ['but', 'she', 'does', \"n't\", 'have'],\n",
              " ['just', 'did', \"n't\", 'know', 'when'],\n",
              " ['laugh', 'and', 'laugh', 'and', 'laugh'],\n",
              " ['seems', 'to', 'have', 'been', 'very'],\n",
              " ['the', 'way', 'to', 'run', 'a'],\n",
              " ['the', 'person', 'with', 'low', 'vision'],\n",
              " ['there', 'is', 'no', 'way', 'a'],\n",
              " ['disposal', 'of', 'out-of-state', 'solid', 'waste'],\n",
              " ['israeli', 'prime', 'minister', 'yitzhak', 'shamir'],\n",
              " ['indeed', 'turn', 'out', 'to', 'be'],\n",
              " ['larry', 'luxner', 'is', 'a', 'freelance'],\n",
              " ['you', 'can', 'pick', 'up', 'an'],\n",
              " ['it', 'is', 'unfortunate', 'that', 'you'],\n",
              " ['says', 'it', 'is', 'willing', 'to'],\n",
              " ['gift', 'horse', 'in', 'the', 'mouth'],\n",
              " ['options', 'remain', 'on', 'the', 'table'],\n",
              " ['was', 'an', 'official', 'of', 'the'],\n",
              " ['at', 'the', 'cusp', 'of', 'the'],\n",
              " ['out', 'as', 'soon', 'as', 'they'],\n",
              " ['expect', 'to', 'be', 'paid', 'for'],\n",
              " ['we', 'do', 'know', 'that', 'in'],\n",
              " ['is', 'the', 'measure', 'of', 'all'],\n",
              " ['did', 'not', 'think', 'that', 'i'],\n",
              " ['same', 'thing', 'happened', 'to', 'the'],\n",
              " ['lives', 'in', 'a', 'world', 'that'],\n",
              " ['who', 'recently', 'stepped', 'down', 'as'],\n",
              " ['are', 'the', 'people', 'with', 'the'],\n",
              " ['the', 'nature', 'of', 'the', 'course'],\n",
              " ['even', 'though', 'it', 'was', 'just'],\n",
              " ['of', 'people', 'did', \"n't\", 'know'],\n",
              " ['to', 'what', 'looks', 'like', 'a'],\n",
              " ['partly', 'because', 'of', 'the', 'way'],\n",
              " ['the', 'united', 'states', 'in', 'latin'],\n",
              " ['the', 'head', 'of', 'the', 'commission'],\n",
              " ['wanted', 'to', 'hear', 'about', 'the'],\n",
              " ['put', 'themselves', 'in', 'the', 'position'],\n",
              " ['not', 'that', 'we', 'want', 'to'],\n",
              " ['this', 'is', 'a', 'strategy', 'that'],\n",
              " ['no', 'clue', 'as', 'to', 'how'],\n",
              " ['curl', 'strengthens', 'biceps', 'brachii', 'and'],\n",
              " ['would', 'be', 'as', 'much', 'as'],\n",
              " ['was', 'on', 'the', 'subject', 'of'],\n",
              " ['number', 'that', 'is', 'expected', 'to'],\n",
              " ['correspondent', 'bill', 'plante', 'has', 'more'],\n",
              " ['can', 'choose', 'from', 'thousands', 'of'],\n",
              " ['power', 'can', 'be', 'used', 'to'],\n",
              " ['happy', 'not', 'to', 'have', 'to'],\n",
              " ['and', 'it', 'came', 'to', 'her'],\n",
              " ['in', 'response', 'to', 'the', 'perceived'],\n",
              " ['with', 'a', 'long', 'nose', 'and'],\n",
              " ['patricia', 'ireland', 'of', 'the', 'national'],\n",
              " ['but', 'i', 'wanted', 'to', 'see'],\n",
              " ['that', 'one', 'day', 'in', 'the'],\n",
              " ['along', 'with', 'the', 'emergence', 'of'],\n",
              " ['has', \"n't\", 'found', 'a', 'job'],\n",
              " ['made', 'his', 'way', 'to', 'his'],\n",
              " ['as', 'the', 'attorney', 'general', 'of'],\n",
              " ['new', 'and', 'existing', 'home', 'sales'],\n",
              " ['i', 'asked', 'a', 'lot', 'of'],\n",
              " ['it', 'was', 'a', 'new', 'york'],\n",
              " ['felt', 'that', 'he', 'was', 'the'],\n",
              " ['to', 'wait', 'for', 'a', 'little'],\n",
              " ['or', 'how', 'much', 'money', 'they'],\n",
              " ['sit', 'for', 'a', 'long', 'time'],\n",
              " ['establish', 'a', 'rapport', 'with', 'the'],\n",
              " [\"n't\", 'you', 'tell', 'me', 'where'],\n",
              " [\"n't\", 'have', 'to', 'change', 'your'],\n",
              " ['because', 'they', 'were', 'dealing', 'with'],\n",
              " ['millions', 'of', 'dollars', 'of', 'the'],\n",
              " ['impeachment', 'trial', 'in', 'the', 'senate'],\n",
              " ['scored', 'significantly', 'higher', 'on', 'the'],\n",
              " ['they', 'arrived', 'in', 'the', 'united'],\n",
              " ['first', 'time', 'that', 'he', 'could'],\n",
              " ['it', 'just', 'does', \"n't\", 'have'],\n",
              " ['essential', 'to', 'the', 'conservation', 'of'],\n",
              " ['i', 'no', 'longer', 'wish', 'to'],\n",
              " ['and', 'in', 'the', 'words', 'of'],\n",
              " ['that', 'he', 'did', \"n't\", 'pay'],\n",
              " ['he', 'turned', 'a', 'blind', 'eye'],\n",
              " ['on', 'the', 'psychological', 'well-being', 'of'],\n",
              " ['down', 'the', 'center', 'of', 'his'],\n",
              " ['have', 'a', 'conversation', 'with', 'him'],\n",
              " ['in', 'las', 'vegas', 'and', 'the'],\n",
              " ['a', 'shake', 'of', 'his', 'head'],\n",
              " ['or', 'as', 'the', 'result', 'of'],\n",
              " ['their', 'wives', 'and', 'their', 'children'],\n",
              " ['the', 'clinton', 'administration', 'and', 'now'],\n",
              " ['a', 'product', 'of', 'the', 'cold'],\n",
              " ['state', 'for', 'a', 'long', 'time'],\n",
              " ['i', 'hate', 'to', 'put', 'it'],\n",
              " ['in', 'order', 'to', 'promote', 'a'],\n",
              " ['wo', \"n't\", 'help', 'if', 'you'],\n",
              " ['it', 'is', 'incredible', 'to', 'me'],\n",
              " ['have', 'the', 'permission', 'of', 'the'],\n",
              " ['he', 'could', \"n't\", 'read', 'or'],\n",
              " ['a', 'few', 'minutes', 'later', 'you'],\n",
              " ['not', 'going', 'to', 'forget', 'what'],\n",
              " ['find', 'a', 'lot', 'of', 'people'],\n",
              " [\"n't\", 'feel', 'as', 'though', 'i'],\n",
              " ['and', 'could', \"n't\", 'find', 'a'],\n",
              " ['abuse', 'is', 'one', 'of', 'the'],\n",
              " ['takes', 'on', 'new', 'meaning', 'when'],\n",
              " ['and', 'a', 'sign', 'that', 'reads'],\n",
              " ['people', 'come', 'to', 'terms', 'with'],\n",
              " ['he', 'is', \"n't\", 'concerned', 'about'],\n",
              " ['you', 'can', 'apply', 'for', 'a'],\n",
              " ['told', 'us', 'he', 'does', \"n't\"],\n",
              " [\"n't\", 'seem', 'to', 'be', 'very'],\n",
              " ['no', 'one', 'has', 'the', 'right'],\n",
              " ['the', 'last', 'few', 'weeks', 'have'],\n",
              " ['to', 'the', 'uniform', 'code', 'of'],\n",
              " ['the', 'notion', 'that', 'he', 'is'],\n",
              " ['hope', 'you', 'stay', 'tuned', 'for'],\n",
              " ['for', 'the', 'deaths', 'of', 'two'],\n",
              " ['say', 'that', 'you', 'ca', \"n't\"],\n",
              " ['one', 'day', 'i', 'said', 'to'],\n",
              " ['after', 'arriving', 'in', 'the', 'united'],\n",
              " ['are', 'back', 'with', 'our', 'roundtable'],\n",
              " ['has', 'no', 'immediate', 'plans', 'to'],\n",
              " ['to', 'be', 'placed', 'on', 'a'],\n",
              " ['as', 'hard', 'as', 'he', 'can'],\n",
              " [\"n't\", 'do', 'them', 'any', 'good'],\n",
              " ['really', 'does', \"n't\", 'like', 'to'],\n",
              " ['a', 'career', 'in', 'special', 'education'],\n",
              " ['one', 'can', 'argue', 'with', 'the'],\n",
              " ['would', 'be', 'hard', 'to', 'find'],\n",
              " ['got', 'his', 'first', 'big', 'break'],\n",
              " ['of', 'the', 'united', 'states', 'do'],\n",
              " ['does', \"n't\", 'have', 'to', 'use'],\n",
              " ['this', 'is', \"n't\", 'really', 'my'],\n",
              " ['and', 'the', 'vast', 'majority', 'are'],\n",
              " ['a', 'way', 'to', 'do', 'things'],\n",
              " ['if', 'he', 'ca', \"n't\", 'get'],\n",
              " ['would', 'you', 'like', 'a', 'piece'],\n",
              " ['seem', 'to', 'be', 'doing', 'anything'],\n",
              " ['there', 'for', 'you', 'when', 'you'],\n",
              " ['trying', 'to', 'reform', 'health', 'care'],\n",
              " ['i', 'doubt', 'it', 'very', 'much'],\n",
              " ['for', 'the', 'pledge', 'of', 'allegiance'],\n",
              " ['there', 'have', 'been', 'some', 'questions'],\n",
              " ['a', 'majority', 'of', 'those', 'polled'],\n",
              " ['the', 'mayor', 'of', 'the', 'city'],\n",
              " ['when', 'we', 'were', 'sitting', 'around'],\n",
              " ['talks', 'for', 'the', 'first', 'time'],\n",
              " ['was', 'walking', 'down', 'the', 'aisle'],\n",
              " ['state', 'and', 'federal', 'law', 'enforcement'],\n",
              " ['to', 'make', 'a', 'difference', 'and'],\n",
              " ['she', 'really', 'did', \"n't\", 'want'],\n",
              " ['a', 'doctor', 'who', 'performed', 'abortions'],\n",
              " ['between', 'public', 'and', 'private', 'interests'],\n",
              " ['to', 'bring', 'the', 'case', 'to'],\n",
              " ['to', 'find', 'new', 'ways', 'of'],\n",
              " ['standards', 'that', 'must', 'be', 'met'],\n",
              " ['there', 'were', 'no', 'people', 'in'],\n",
              " ['the', 'idea', 'that', 'we', 'ought'],\n",
              " ['on', 'the', 'plane', 'ride', 'home'],\n",
              " ['in', 'two', 'places', 'at', 'once'],\n",
              " ['to', 'go', 'to', 'someone', 'else'],\n",
              " ['want', 'to', 'live', 'with', 'her'],\n",
              " ['how', 'does', 'it', 'happen', 'that'],\n",
              " ['with', 'a', 'sprig', 'of', 'mint'],\n",
              " ['the', 'administration', 'and', 'enforcement', 'of'],\n",
              " ['the', 'heritage', 'culture', 'and', 'language'],\n",
              " ['may', 'be', 'appropriate', 'in', 'some'],\n",
              " ['get', 'the', 'feeling', 'that', 'people'],\n",
              " ['for', 'the', 'presidency', 'on', 'the'],\n",
              " ['the', 'first', 'one', 'or', 'two'],\n",
              " ['happened', 'in', 'the', 'case', 'of'],\n",
              " ['his', 'first', 'season', 'in', 'the'],\n",
              " ['the', 'hottest', 'days', 'of', 'the'],\n",
              " ['to', 'make', 'a', 'living', 'and'],\n",
              " ['wife', 'and', 'two', 'young', 'daughters'],\n",
              " ['we', 'could', 'all', 'use', 'a'],\n",
              " ['not', 'required', 'to', 'do', 'so'],\n",
              " ['at', 'least', 'not', 'at', 'first'],\n",
              " ['were', 'the', 'head', 'of', 'the'],\n",
              " ['to', 'be', 'in', 'the', 'park'],\n",
              " ['the', 'guy', 'who', 'can', 'get'],\n",
              " ['some', 'of', 'the', 'states', 'that'],\n",
              " ['for', 'the', 'average', 'investor', 'to'],\n",
              " ['strikes', 'fear', 'in', 'the', 'hearts'],\n",
              " ['enough', 'to', 'be', 'called', 'a'],\n",
              " [\"n't\", 'trade', 'them', 'for', 'anything'],\n",
              " ['center', 'comes', 'out', 'clean', 'and'],\n",
              " ['i', 'do', \"n't\", 'understand', 'some'],\n",
              " ['so', 'we', 'could', 'have', 'a'],\n",
              " ['a', 'broad', 'understanding', 'of', 'the'],\n",
              " ['can', 'also', 'visit', 'the', 'company'],\n",
              " ['the', 'rural', 'and', 'urban', 'poor'],\n",
              " ['as', 'much', 'as', 'it', 'bothers'],\n",
              " ['can', 'be', 'an', 'effective', 'tool'],\n",
              " ['charcoal', 'on', 'marble-dusted', 'drawing', 'board'],\n",
              " ['but', 'she', 'knows', 'that', 'she'],\n",
              " ['one', 'to', 'care', 'for', 'them'],\n",
              " ['to', 'bring', 'pressure', 'to', 'bear'],\n",
              " ['what', 'is', 'the', 'character', 'of'],\n",
              " ['walker', 'of', 'the', 'national', 'enquirer'],\n",
              " ['occupation', 'of', 'the', 'west', 'bank'],\n",
              " ['they', 'knew', 'what', 'it', 'was'],\n",
              " ['the', 'present', 'study', 'and', 'the'],\n",
              " ['had', 'come', 'to', 'a', 'point'],\n",
              " ['they', 'thought', 'he', 'was', 'going'],\n",
              " ['i', 'suspect', 'that', 'in', 'the'],\n",
              " ['the', 'side', 'of', 'the', 'old'],\n",
              " ['biomechanics', 'of', 'the', 'musculoskeletal', 'system'],\n",
              " ['joins', 'us', 'now', 'from', 'los'],\n",
              " ['this', 'is', 'what', 'he', 'wants'],\n",
              " ['with', 'him', 'the', 'night', 'before'],\n",
              " ['he', 'followed', 'her', 'in', 'his'],\n",
              " ['were', 'not', 'even', 'allowed', 'to'],\n",
              " ['of', 'the', 'trial', 'and', 'the'],\n",
              " ['i', 'really', 'want', 'people', 'to'],\n",
              " ['not', 'going', 'to', 'be', 'happy'],\n",
              " ['than', 'three', 'times', 'that', 'of'],\n",
              " ['put', 'everything', 'he', 'had', 'into'],\n",
              " ['to', 'be', 'seen', 'and', 'not'],\n",
              " ['and', 'the', 'author', 'of', 'how'],\n",
              " ['of', 'their', 'income', 'for', 'rent'],\n",
              " ['there', 'are', 'pros', 'and', 'cons'],\n",
              " ['so', 'it', 'should', \"n't\", 'be'],\n",
              " ['to', 'be', 'a', 'fighter', 'pilot'],\n",
              " ['is', 'that', 'people', 'do', 'not'],\n",
              " ['to', 'the', 'early', 'show', 'everyone'],\n",
              " ['do', \"n't\", 'think', 'it', 'looks'],\n",
              " ['this', 'season', 'is', 'all', 'about'],\n",
              " ['sense', 'of', 'who', 'he', 'was'],\n",
              " ['are', 'going', 'to', 'be', 'making'],\n",
              " [\"n't\", 'have', 'to', 'spend', 'money'],\n",
              " ['was', 'asked', 'to', 'write', 'about'],\n",
              " ...]"
            ]
          },
          "execution_count": 328,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "val_storage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 329,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>modified_sentence</th>\n",
              "      <th>modified_word_idxs</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[that, might, bbmee, interpreted, as]</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[made, a, lobt, of, sacrifices]</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[plant, biological, ad, molecular, processes]</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[no, reason, wmvy, they, should]</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[and, he, ofld, her, he]</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104422</th>\n",
              "      <td>[what, else, a, we, do]</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104423</th>\n",
              "      <td>[too, much, emphass, is, placed]</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104424</th>\n",
              "      <td>[the, purpose, oc, having, a]</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104425</th>\n",
              "      <td>[gazing, up, xt, the, stars]</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104426</th>\n",
              "      <td>[he, takes, y, hand, and]</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>104427 rows  2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                    modified_sentence modified_word_idxs\n",
              "0               [that, might, bbmee, interpreted, as]                  2\n",
              "1                     [made, a, lobt, of, sacrifices]                  2\n",
              "2       [plant, biological, ad, molecular, processes]                  2\n",
              "3                    [no, reason, wmvy, they, should]                  2\n",
              "4                            [and, he, ofld, her, he]                  2\n",
              "...                                               ...                ...\n",
              "104422                        [what, else, a, we, do]                  2\n",
              "104423               [too, much, emphass, is, placed]                  2\n",
              "104424                  [the, purpose, oc, having, a]                  2\n",
              "104425                   [gazing, up, xt, the, stars]                  2\n",
              "104426                      [he, takes, y, hand, and]                  2\n",
              "\n",
              "[104427 rows x 2 columns]"
            ]
          },
          "execution_count": 329,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "val_res = generate_modified_set(val_storage)\n",
        "val_res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 330,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>modified_sentence</th>\n",
              "      <th>modified_word_idxs</th>\n",
              "      <th>original_sent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[that, might, bbmee, interpreted, as]</td>\n",
              "      <td>2</td>\n",
              "      <td>[that, might, be, interpreted, as]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[made, a, lobt, of, sacrifices]</td>\n",
              "      <td>2</td>\n",
              "      <td>[made, a, lot, of, sacrifices]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[plant, biological, ad, molecular, processes]</td>\n",
              "      <td>2</td>\n",
              "      <td>[plant, biological, and, molecular, processes]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[no, reason, wmvy, they, should]</td>\n",
              "      <td>2</td>\n",
              "      <td>[no, reason, why, they, should]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[and, he, ofld, her, he]</td>\n",
              "      <td>2</td>\n",
              "      <td>[and, he, told, her, he]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104422</th>\n",
              "      <td>[what, else, a, we, do]</td>\n",
              "      <td>2</td>\n",
              "      <td>[what, else, can, we, do]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104423</th>\n",
              "      <td>[too, much, emphass, is, placed]</td>\n",
              "      <td>2</td>\n",
              "      <td>[too, much, emphasis, is, placed]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104424</th>\n",
              "      <td>[the, purpose, oc, having, a]</td>\n",
              "      <td>2</td>\n",
              "      <td>[the, purpose, of, having, a]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104425</th>\n",
              "      <td>[gazing, up, xt, the, stars]</td>\n",
              "      <td>2</td>\n",
              "      <td>[gazing, up, at, the, stars]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104426</th>\n",
              "      <td>[he, takes, y, hand, and]</td>\n",
              "      <td>2</td>\n",
              "      <td>[he, takes, my, hand, and]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>104427 rows  3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                    modified_sentence modified_word_idxs  \\\n",
              "0               [that, might, bbmee, interpreted, as]                  2   \n",
              "1                     [made, a, lobt, of, sacrifices]                  2   \n",
              "2       [plant, biological, ad, molecular, processes]                  2   \n",
              "3                    [no, reason, wmvy, they, should]                  2   \n",
              "4                            [and, he, ofld, her, he]                  2   \n",
              "...                                               ...                ...   \n",
              "104422                        [what, else, a, we, do]                  2   \n",
              "104423               [too, much, emphass, is, placed]                  2   \n",
              "104424                  [the, purpose, oc, having, a]                  2   \n",
              "104425                   [gazing, up, xt, the, stars]                  2   \n",
              "104426                      [he, takes, y, hand, and]                  2   \n",
              "\n",
              "                                         original_sent  \n",
              "0                   [that, might, be, interpreted, as]  \n",
              "1                       [made, a, lot, of, sacrifices]  \n",
              "2       [plant, biological, and, molecular, processes]  \n",
              "3                      [no, reason, why, they, should]  \n",
              "4                             [and, he, told, her, he]  \n",
              "...                                                ...  \n",
              "104422                       [what, else, can, we, do]  \n",
              "104423               [too, much, emphasis, is, placed]  \n",
              "104424                   [the, purpose, of, having, a]  \n",
              "104425                    [gazing, up, at, the, stars]  \n",
              "104426                      [he, takes, my, hand, and]  \n",
              "\n",
              "[104427 rows x 3 columns]"
            ]
          },
          "execution_count": 330,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "val_res['original_sent'] = val_storage\n",
        "val_res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 331,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([2, 'do', 'up', 'to', 'be', 'me', 'at', 'on', 'we', 'as', 'of',\n",
              "       'us', 'it', 'is', 'go', 'if', 'i', 'he', 'or', 'na', 'so', 'tv',\n",
              "       'a', 'es', 'an', 'f'], dtype=object)"
            ]
          },
          "execution_count": 331,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "val_res.loc[:, 'modified_word_idxs'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 332,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>modified_sentence</th>\n",
              "      <th>modified_word_idxs</th>\n",
              "      <th>original_sent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>to</td>\n",
              "      <td>do</td>\n",
              "      <td>[to, do, is, to, write]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>206</th>\n",
              "      <td>showed</td>\n",
              "      <td>up</td>\n",
              "      <td>[showed, up, at, my, door]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>211</th>\n",
              "      <td>ways</td>\n",
              "      <td>to</td>\n",
              "      <td>[ways, to, do, it, is]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>253</th>\n",
              "      <td>going</td>\n",
              "      <td>to</td>\n",
              "      <td>[going, to, go, do, that]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>481</th>\n",
              "      <td>to</td>\n",
              "      <td>be</td>\n",
              "      <td>[to, be, in, an, area]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103631</th>\n",
              "      <td>up</td>\n",
              "      <td>to</td>\n",
              "      <td>[up, to, go, to, work]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103797</th>\n",
              "      <td>had</td>\n",
              "      <td>to</td>\n",
              "      <td>[had, to, do, to, make]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103983</th>\n",
              "      <td>going</td>\n",
              "      <td>to</td>\n",
              "      <td>[going, to, be, a, quick]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104041</th>\n",
              "      <td>came</td>\n",
              "      <td>up</td>\n",
              "      <td>[came, up, to, me, and]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104155</th>\n",
              "      <td>next</td>\n",
              "      <td>to</td>\n",
              "      <td>[next, to, me, on, the]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>764 rows  3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       modified_sentence modified_word_idxs               original_sent\n",
              "15                    to                 do     [to, do, is, to, write]\n",
              "206               showed                 up  [showed, up, at, my, door]\n",
              "211                 ways                 to      [ways, to, do, it, is]\n",
              "253                going                 to   [going, to, go, do, that]\n",
              "481                   to                 be      [to, be, in, an, area]\n",
              "...                  ...                ...                         ...\n",
              "103631                up                 to      [up, to, go, to, work]\n",
              "103797               had                 to     [had, to, do, to, make]\n",
              "103983             going                 to   [going, to, be, a, quick]\n",
              "104041              came                 up     [came, up, to, me, and]\n",
              "104155              next                 to     [next, to, me, on, the]\n",
              "\n",
              "[764 rows x 3 columns]"
            ]
          },
          "execution_count": 332,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "val_res.loc[(val_res.loc[:, 'modified_word_idxs'] != 1) & (val_res.loc[:, 'modified_word_idxs'] != 2) & (val_res.loc[:, 'modified_word_idxs'] != 3), :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 333,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>modified_sentence</th>\n",
              "      <th>modified_word_idxs</th>\n",
              "      <th>original_sent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[that, might, bbmee, interpreted, as]</td>\n",
              "      <td>2</td>\n",
              "      <td>[that, might, be, interpreted, as]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[made, a, lobt, of, sacrifices]</td>\n",
              "      <td>2</td>\n",
              "      <td>[made, a, lot, of, sacrifices]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[plant, biological, ad, molecular, processes]</td>\n",
              "      <td>2</td>\n",
              "      <td>[plant, biological, and, molecular, processes]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[no, reason, wmvy, they, should]</td>\n",
              "      <td>2</td>\n",
              "      <td>[no, reason, why, they, should]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[and, he, ofld, her, he]</td>\n",
              "      <td>2</td>\n",
              "      <td>[and, he, told, her, he]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103658</th>\n",
              "      <td>[what, else, a, we, do]</td>\n",
              "      <td>2</td>\n",
              "      <td>[what, else, can, we, do]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103659</th>\n",
              "      <td>[too, much, emphass, is, placed]</td>\n",
              "      <td>2</td>\n",
              "      <td>[too, much, emphasis, is, placed]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103660</th>\n",
              "      <td>[the, purpose, oc, having, a]</td>\n",
              "      <td>2</td>\n",
              "      <td>[the, purpose, of, having, a]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103661</th>\n",
              "      <td>[gazing, up, xt, the, stars]</td>\n",
              "      <td>2</td>\n",
              "      <td>[gazing, up, at, the, stars]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103662</th>\n",
              "      <td>[he, takes, y, hand, and]</td>\n",
              "      <td>2</td>\n",
              "      <td>[he, takes, my, hand, and]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>103663 rows  3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                    modified_sentence modified_word_idxs  \\\n",
              "0               [that, might, bbmee, interpreted, as]                  2   \n",
              "1                     [made, a, lobt, of, sacrifices]                  2   \n",
              "2       [plant, biological, ad, molecular, processes]                  2   \n",
              "3                    [no, reason, wmvy, they, should]                  2   \n",
              "4                            [and, he, ofld, her, he]                  2   \n",
              "...                                               ...                ...   \n",
              "103658                        [what, else, a, we, do]                  2   \n",
              "103659               [too, much, emphass, is, placed]                  2   \n",
              "103660                  [the, purpose, oc, having, a]                  2   \n",
              "103661                   [gazing, up, xt, the, stars]                  2   \n",
              "103662                      [he, takes, y, hand, and]                  2   \n",
              "\n",
              "                                         original_sent  \n",
              "0                   [that, might, be, interpreted, as]  \n",
              "1                       [made, a, lot, of, sacrifices]  \n",
              "2       [plant, biological, and, molecular, processes]  \n",
              "3                      [no, reason, why, they, should]  \n",
              "4                             [and, he, told, her, he]  \n",
              "...                                                ...  \n",
              "103658                       [what, else, can, we, do]  \n",
              "103659               [too, much, emphasis, is, placed]  \n",
              "103660                   [the, purpose, of, having, a]  \n",
              "103661                    [gazing, up, at, the, stars]  \n",
              "103662                      [he, takes, my, hand, and]  \n",
              "\n",
              "[103663 rows x 3 columns]"
            ]
          },
          "execution_count": 333,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Remove such outliers\n",
        "val_df = val_res.loc[(val_res.loc[:, 'modified_word_idxs'] == 1) | (val_res.loc[:, 'modified_word_idxs'] == 2) | (val_res.loc[:, 'modified_word_idxs'] == 3), :].reset_index(drop=True)\n",
        "val_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 334,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([2], dtype=object)"
            ]
          },
          "execution_count": 334,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "val_df.loc[:, 'modified_word_idxs'].unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Test Norvig's Corrector on validation set\n",
        "Note that Norvig's Corrector does not take into the count neighboring words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 361,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c9d83f771aea4c3aacdd15024a7514bd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/103663 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Elements passed: 0. Accuracy: 0.0000\n",
            "Current correction result: bee. Word: be\n",
            "Elements passed: 1000. Accuracy: 0.0053\n",
            "Current correction result: a. Word: i\n",
            "Elements passed: 2000. Accuracy: 0.0101\n",
            "Current correction result: similar. Word: similar\n",
            "Elements passed: 3000. Accuracy: 0.0152\n",
            "Current correction result: have. Word: have\n",
            "Elements passed: 4000. Accuracy: 0.0204\n",
            "Current correction result: a. Word: a\n",
            "Elements passed: 5000. Accuracy: 0.0255\n",
            "Current correction result: same. Word: seem\n",
            "Elements passed: 6000. Accuracy: 0.0306\n",
            "Current correction result: to. Word: up\n",
            "Elements passed: 7000. Accuracy: 0.0358\n",
            "Current correction result: farm. Word: fat\n",
            "Elements passed: 8000. Accuracy: 0.0409\n",
            "Current correction result: that. Word: that\n",
            "Elements passed: 9000. Accuracy: 0.0461\n",
            "Current correction result: mm. Word: form\n",
            "Elements passed: 10000. Accuracy: 0.0513\n",
            "Current correction result: earlier. Word: earlier\n",
            "Elements passed: 11000. Accuracy: 0.0562\n",
            "Current correction result: needs. Word: needs\n",
            "Elements passed: 12000. Accuracy: 0.0615\n",
            "Current correction result: off. Word: of\n",
            "Elements passed: 13000. Accuracy: 0.0664\n",
            "Current correction result: do. Word: do\n",
            "Elements passed: 14000. Accuracy: 0.0712\n",
            "Current correction result: you. Word: you\n",
            "Elements passed: 15000. Accuracy: 0.0762\n",
            "Current correction result: people. Word: people\n",
            "Elements passed: 16000. Accuracy: 0.0815\n",
            "Current correction result: building. Word: building\n",
            "Elements passed: 17000. Accuracy: 0.0865\n",
            "Current correction result: dear. Word: hear\n",
            "Elements passed: 18000. Accuracy: 0.0917\n",
            "Current correction result: umm. Word: much\n",
            "Elements passed: 19000. Accuracy: 0.0971\n",
            "Current correction result: as. Word: so\n",
            "Elements passed: 20000. Accuracy: 0.1022\n",
            "Current correction result: he. Word: he\n",
            "Elements passed: 21000. Accuracy: 0.1072\n",
            "Current correction result: minutes. Word: minutes\n",
            "Elements passed: 22000. Accuracy: 0.1125\n",
            "Current correction result: was. Word: what\n",
            "Elements passed: 23000. Accuracy: 0.1178\n",
            "Current correction result: of. Word: of\n",
            "Elements passed: 24000. Accuracy: 0.1230\n",
            "Current correction result: at. Word: last\n",
            "Elements passed: 25000. Accuracy: 0.1283\n",
            "Current correction result: nat. Word: great\n",
            "Elements passed: 26000. Accuracy: 0.1333\n",
            "Current correction result: wags. Word: wages\n",
            "Elements passed: 27000. Accuracy: 0.1383\n",
            "Current correction result: s. Word: as\n",
            "Elements passed: 28000. Accuracy: 0.1431\n",
            "Current correction result: he. Word: the\n",
            "Elements passed: 29000. Accuracy: 0.1482\n",
            "Current correction result: center. Word: center\n",
            "Elements passed: 30000. Accuracy: 0.1533\n",
            "Current correction result: a. Word: to\n",
            "Elements passed: 31000. Accuracy: 0.1584\n",
            "Current correction result: o. Word: do\n",
            "Elements passed: 32000. Accuracy: 0.1635\n",
            "Current correction result: the. Word: the\n",
            "Elements passed: 33000. Accuracy: 0.1685\n",
            "Current correction result: to. Word: to\n",
            "Elements passed: 34000. Accuracy: 0.1734\n",
            "Current correction result: trial. Word: trial\n",
            "Elements passed: 35000. Accuracy: 0.1784\n",
            "Current correction result: luxury. Word: luxury\n",
            "Elements passed: 36000. Accuracy: 0.1836\n",
            "Current correction result: would. Word: would\n",
            "Elements passed: 37000. Accuracy: 0.1888\n",
            "Current correction result: the. Word: the\n",
            "Elements passed: 38000. Accuracy: 0.1936\n",
            "Current correction result: one. Word: more\n",
            "Elements passed: 39000. Accuracy: 0.1985\n",
            "Current correction result: to. Word: told\n",
            "Elements passed: 40000. Accuracy: 0.2037\n",
            "Current correction result: all. Word: deal\n",
            "Elements passed: 41000. Accuracy: 0.2087\n",
            "Current correction result: dime. Word: time\n",
            "Elements passed: 42000. Accuracy: 0.2138\n",
            "Current correction result: or. Word: for\n",
            "Elements passed: 43000. Accuracy: 0.2188\n",
            "Current correction result: all. Word: call\n",
            "Elements passed: 44000. Accuracy: 0.2240\n",
            "Current correction result: the. Word: the\n",
            "Elements passed: 45000. Accuracy: 0.2292\n",
            "Current correction result: just. Word: just\n",
            "Elements passed: 46000. Accuracy: 0.2345\n",
            "Current correction result: people. Word: people\n",
            "Elements passed: 47000. Accuracy: 0.2397\n",
            "Current correction result: off. Word: of\n",
            "Elements passed: 48000. Accuracy: 0.2448\n",
            "Current correction result: of. Word: of\n",
            "Elements passed: 49000. Accuracy: 0.2500\n",
            "Current correction result: sort. Word: court\n",
            "Elements passed: 50000. Accuracy: 0.2553\n",
            "Current correction result: b. Word: up\n",
            "Elements passed: 51000. Accuracy: 0.2605\n",
            "Current correction result: tyco. Word: to\n",
            "Elements passed: 52000. Accuracy: 0.2656\n",
            "Current correction result: tm. Word: to\n",
            "Elements passed: 53000. Accuracy: 0.2707\n",
            "Current correction result: inn. Word: in\n",
            "Elements passed: 54000. Accuracy: 0.2758\n",
            "Current correction result: ave. Word: have\n",
            "Elements passed: 55000. Accuracy: 0.2808\n",
            "Current correction result: n't. Word: n't\n",
            "Elements passed: 56000. Accuracy: 0.2859\n",
            "Current correction result: know. Word: own\n",
            "Elements passed: 57000. Accuracy: 0.2913\n",
            "Current correction result: who. Word: of\n",
            "Elements passed: 58000. Accuracy: 0.2966\n",
            "Current correction result: gi. Word: give\n",
            "Elements passed: 59000. Accuracy: 0.3018\n",
            "Current correction result: new. Word: new\n",
            "Elements passed: 60000. Accuracy: 0.3065\n",
            "Current correction result: c. Word: to\n",
            "Elements passed: 61000. Accuracy: 0.3112\n",
            "Current correction result: possibility. Word: possibility\n",
            "Elements passed: 62000. Accuracy: 0.3163\n",
            "Current correction result: he. Word: had\n",
            "Elements passed: 63000. Accuracy: 0.3210\n",
            "Current correction result: he. Word: her\n",
            "Elements passed: 64000. Accuracy: 0.3260\n",
            "Current correction result: a. Word: to\n",
            "Elements passed: 65000. Accuracy: 0.3309\n",
            "Current correction result: bin. Word: in\n",
            "Elements passed: 66000. Accuracy: 0.3360\n",
            "Current correction result: clear. Word: car\n",
            "Elements passed: 67000. Accuracy: 0.3411\n",
            "Current correction result: only. Word: only\n",
            "Elements passed: 68000. Accuracy: 0.3462\n",
            "Current correction result: o. Word: to\n",
            "Elements passed: 69000. Accuracy: 0.3513\n",
            "Current correction result: come. Word: come\n",
            "Elements passed: 70000. Accuracy: 0.3564\n",
            "Current correction result: it. Word: it\n",
            "Elements passed: 71000. Accuracy: 0.3616\n",
            "Current correction result: do. Word: to\n",
            "Elements passed: 72000. Accuracy: 0.3669\n",
            "Current correction result: matter. Word: matter\n",
            "Elements passed: 73000. Accuracy: 0.3719\n",
            "Current correction result: was. Word: was\n",
            "Elements passed: 74000. Accuracy: 0.3771\n",
            "Current correction result: zoo. Word: go\n",
            "Elements passed: 75000. Accuracy: 0.3819\n",
            "Current correction result: knee. Word: be\n",
            "Elements passed: 76000. Accuracy: 0.3871\n",
            "Current correction result: found. Word: round\n",
            "Elements passed: 77000. Accuracy: 0.3923\n",
            "Current correction result: ne. Word: make\n",
            "Elements passed: 78000. Accuracy: 0.3973\n",
            "Current correction result: and. Word: and\n",
            "Elements passed: 79000. Accuracy: 0.4025\n",
            "Current correction result: people. Word: people\n",
            "Elements passed: 80000. Accuracy: 0.4077\n",
            "Current correction result: the. Word: that\n",
            "Elements passed: 81000. Accuracy: 0.4127\n",
            "Current correction result: learn. Word: learn\n",
            "Elements passed: 82000. Accuracy: 0.4178\n",
            "Current correction result: it. Word: it\n",
            "Elements passed: 83000. Accuracy: 0.4230\n",
            "Current correction result: her. Word: her\n",
            "Elements passed: 84000. Accuracy: 0.4283\n",
            "Current correction result: a. Word: a\n",
            "Elements passed: 85000. Accuracy: 0.4333\n",
            "Current correction result: name. Word: name\n",
            "Elements passed: 86000. Accuracy: 0.4382\n",
            "Current correction result: it. Word: to\n",
            "Elements passed: 87000. Accuracy: 0.4434\n",
            "Current correction result: a. Word: a\n",
            "Elements passed: 88000. Accuracy: 0.4489\n",
            "Current correction result: it. Word: at\n",
            "Elements passed: 89000. Accuracy: 0.4542\n",
            "Current correction result: community. Word: community\n",
            "Elements passed: 90000. Accuracy: 0.4594\n",
            "Current correction result: expecting. Word: expecting\n",
            "Elements passed: 91000. Accuracy: 0.4645\n",
            "Current correction result: had. Word: had\n",
            "Elements passed: 92000. Accuracy: 0.4698\n",
            "Current correction result: both. Word: other\n",
            "Elements passed: 93000. Accuracy: 0.4750\n",
            "Current correction result: think. Word: think\n",
            "Elements passed: 94000. Accuracy: 0.4799\n",
            "Current correction result: n't. Word: n't\n",
            "Elements passed: 95000. Accuracy: 0.4854\n",
            "Current correction result: eat. Word: exact\n",
            "Elements passed: 96000. Accuracy: 0.4903\n",
            "Current correction result: what. Word: want\n",
            "Elements passed: 97000. Accuracy: 0.4956\n",
            "Current correction result: teh. Word: the\n",
            "Elements passed: 98000. Accuracy: 0.5006\n",
            "Current correction result: the. Word: the\n",
            "Elements passed: 99000. Accuracy: 0.5057\n",
            "Current correction result: long. Word: on\n",
            "Elements passed: 100000. Accuracy: 0.5108\n",
            "Current correction result: period. Word: period\n",
            "Elements passed: 101000. Accuracy: 0.5158\n",
            "Current correction result: a. Word: a\n",
            "Elements passed: 102000. Accuracy: 0.5208\n",
            "Current correction result: inn. Word: in\n",
            "Elements passed: 103000. Accuracy: 0.5258\n",
            "Current correction result: the. Word: the\n",
            "Norvig Corrector accuracy of validation set: 0.5294\n"
          ]
        }
      ],
      "source": [
        "right_corrections_count = 0\n",
        "\n",
        "for val_row in tqdm(val_df.iterrows(), total=val_df.shape[0]):\n",
        "    if val_row[0] % 1000 == 0:\n",
        "        print(f\"Elements passed: {val_row[0]}. Accuracy: {(right_corrections_count / val_df.shape[0]):.4f}\")\n",
        "        print(f\"Current correction result: {norvig_corrector.correction(val_row[1].loc['modified_sentence'][word_idx])}. Word: {val_row[1].loc['original_sent'][word_idx]}\")\n",
        "        \n",
        "    word_idx = val_row[1].loc['modified_word_idxs']\n",
        "    if val_row[1].loc['original_sent'][word_idx] == norvig_corrector.correction(val_row[1].loc['modified_sentence'][word_idx]):\n",
        "        right_corrections_count += 1\n",
        "    \n",
        "print(f\"Norvig Corrector accuracy of validation set: {(right_corrections_count / val_df.shape[0]):.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As you can see we managed to achieve ~53% accuracy on validation set using simplest Norvig's Corrector model implementation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "However, right now there are 2 unsolved problems:\n",
        "- Accuracy can be improved;\n",
        "- Model does not use other words in given sentences."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Improve the basic implementation of Norvig's Corrector by adding the context usign N-Gram models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### This section will be splitted into 2 parts:\n",
        "- `NGramModel` class implementation;\n",
        "- `NGramNorvigCorrector` class implementation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 335,
      "metadata": {},
      "outputs": [],
      "source": [
        "class NGramModel():\n",
        "\n",
        "    def __init__(self, ngram_sent: list[list[str]], n: int = 3) -> None:\n",
        "        \"\"\"\n",
        "        Initialize the N-Gram language model.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        ngram_sent: list[list[str]]\n",
        "            List that contains sentences of fivegrams.\n",
        "        n: int = 3\n",
        "            The amount of words contained in each N-Gram.\n",
        "        \"\"\"\n",
        "\n",
        "        self.n = n\n",
        "        self.ngram_count = defaultdict(Counter)\n",
        "        self.context_count = defaultdict(int)\n",
        "\n",
        "        for ngram in ngram_sent:\n",
        "            for i in range(len(ngram) - n + 1):\n",
        "                cur_context = tuple(ngram[i:i + n - 1])\n",
        "                word = ngram[i + n - 1]\n",
        "                self.ngram_count[cur_context][word] += 1\n",
        "                self.context_count[cur_context] += 1\n",
        "\n",
        "    def P(self, word: str, context: defaultdict) -> float:\n",
        "        \"\"\"\n",
        "        Calculate the probability of a word given its context.\n",
        "        \"\"\"\n",
        "\n",
        "        context = tuple(context)\n",
        "        if context in self.ngram_count:\n",
        "            return self.ngram_count[context][word] / self.context_count[context]\n",
        "        else:\n",
        "            return 0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 336,
      "metadata": {},
      "outputs": [],
      "source": [
        "class NGramNorvigCorrector():\n",
        "\n",
        "    def __init__(self, train_storage_dict: defaultdict, ngram_model: NGramModel) -> None:\n",
        "        \"\"\"\n",
        "        Initialize the NorvigCorrector with N-Gram model.\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        train_dict: Counter\n",
        "            Counter object that contains the amount of each word that is encountered in training text.\n",
        "        ngram_model: NGramModel\n",
        "            An instance of the N-Gram language model.\n",
        "        \"\"\"\n",
        "        \n",
        "        self.train_dict = train_storage_dict\n",
        "        self.N = sum(train_storage_dict.values())\n",
        "        self.ngram_model = ngram_model\n",
        "\n",
        "    def P(self, word: str, N=None) -> float:\n",
        "        \"\"\"\n",
        "        Calculate probability of given word.\n",
        "        \"\"\"\n",
        "\n",
        "        if N is None:\n",
        "            N = self.N\n",
        "        return self.train_dict[word] / N\n",
        "\n",
        "    def correction(self, word: str, context: defaultdict) -> str:\n",
        "        \"\"\"\n",
        "        Find most probable spelling correction for given word, considering the context.\n",
        "        \"\"\"\n",
        "\n",
        "        candidates = self.candidates(word)\n",
        "        \n",
        "        if not candidates:\n",
        "            return word\n",
        "        \n",
        "        candidate_proba = []\n",
        "        for candidate in candidates:\n",
        "            word_proba = self.P(candidate)\n",
        "            context_proba = self.ngram_model.P(candidate, context)\n",
        "            #combined_proba = word_proba * context_proba\n",
        "            # Try to add probabilitites instead of multiplying\n",
        "            combined_proba = word_proba + context_proba\n",
        "            candidate_proba.append((candidate, combined_proba))\n",
        "        \n",
        "        return max(candidate_proba, key=lambda x: x[1])[0]\n",
        "    \n",
        "    def candidates(self, word: str) -> set:\n",
        "        \"\"\"\n",
        "        Generate possible spelling corrections for given word.\n",
        "        \"\"\"\n",
        "\n",
        "        return (self.known([word]) or self.known(self.edits1(word))\n",
        "                or self.known(self.edits2(word)) or [word])\n",
        "    \n",
        "    def known(self, words: str | list[str]) -> set:\n",
        "        \"\"\"\n",
        "        Find the subset of words that appear in the dictionary of `NorvigCorrector.train_words`.\n",
        "        \"\"\"\n",
        "\n",
        "        return set(w for w in words if w in self.train_dict.keys())\n",
        "    \n",
        "    def edits1(self, word: str) -> set:\n",
        "        \"\"\"\n",
        "        Generate all possible edits that are one edit away from given word.\n",
        "        \"\"\"\n",
        "\n",
        "        letters = 'abcdefghijklmnopqrstuvwxyz'\n",
        "        splits = [(word[:i], word[i:]) for i in range(len(word) + 1)]\n",
        "        deletes = [L + R[1:] for L, R in splits if R]\n",
        "        transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R) > 1]\n",
        "        replaces = [L + c + R[1:] for L, R in splits if R for c in letters]\n",
        "        inserts = [L + c + R for L, R in splits for c in letters]\n",
        "        return set(deletes + transposes + replaces + inserts)\n",
        "    \n",
        "    def edits2(self, word: str) -> set:\n",
        "        \"\"\"\n",
        "        Generate all possible edits that are two edits away from given word.\n",
        "        \"\"\"\n",
        "        \n",
        "        return (e2 for e1 in self.edits1(word) for e2 in self.edits1(e1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 337,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_storage_dict = Counter(word for ngram in train_storage for word in ngram)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 338,
      "metadata": {},
      "outputs": [],
      "source": [
        "ngram_model = NGramModel(train_storage)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 339,
      "metadata": {},
      "outputs": [],
      "source": [
        "ngram_norvig_corrector = NGramNorvigCorrector(train_storage_dict, ngram_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 349,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original test example: ['do', \"n't\", 'understand', 'where', 'the'].\n",
            " Modified test example: ['do', \"n't\", 'unpderstand', 'where', 'the'].\n"
          ]
        }
      ],
      "source": [
        "test_example = random.choice(train_storage)\n",
        "modified_test_example = modify_list(test_example)\n",
        "word_number = modified_test_example[1]\n",
        "print(f\"Original test example: {test_example}.\\n Modified test example: {modified_test_example[0]}.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 350,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['do', \"n't\"]"
            ]
          },
          "execution_count": 350,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "modified_test_example[0][:word_number]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 351,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'understand'"
            ]
          },
          "execution_count": 351,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ngram_norvig_corrector.correction(modified_test_example[0][word_number], modified_test_example[0][:word_number])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 352,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'unpderstand'"
            ]
          },
          "execution_count": 352,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "modified_test_example[0][word_number]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Test the upgraded Norvig's Corrector on validation dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 353,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2c66e6c998c54d2bae233aa27f8783e0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/103663 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Elements passed: 0. Accuracy: 0.0000\n",
            "Current correction result: bee. Word: be\n",
            "Elements passed: 1000. Accuracy: 0.0058\n",
            "Current correction result: i. Word: i\n",
            "Elements passed: 2000. Accuracy: 0.0113\n",
            "Current correction result: similar. Word: similar\n",
            "Elements passed: 3000. Accuracy: 0.0171\n",
            "Current correction result: have. Word: have\n",
            "Elements passed: 4000. Accuracy: 0.0228\n",
            "Current correction result: a. Word: a\n",
            "Elements passed: 5000. Accuracy: 0.0286\n",
            "Current correction result: seem. Word: seem\n",
            "Elements passed: 6000. Accuracy: 0.0343\n",
            "Current correction result: up. Word: up\n",
            "Elements passed: 7000. Accuracy: 0.0400\n",
            "Current correction result: farm. Word: fat\n",
            "Elements passed: 8000. Accuracy: 0.0457\n",
            "Current correction result: that. Word: that\n",
            "Elements passed: 9000. Accuracy: 0.0515\n",
            "Current correction result: mm. Word: form\n",
            "Elements passed: 10000. Accuracy: 0.0573\n",
            "Current correction result: earlier. Word: earlier\n",
            "Elements passed: 11000. Accuracy: 0.0629\n",
            "Current correction result: needs. Word: needs\n",
            "Elements passed: 12000. Accuracy: 0.0688\n",
            "Current correction result: off. Word: of\n",
            "Elements passed: 13000. Accuracy: 0.0744\n",
            "Current correction result: do. Word: do\n",
            "Elements passed: 14000. Accuracy: 0.0798\n",
            "Current correction result: you. Word: you\n",
            "Elements passed: 15000. Accuracy: 0.0853\n",
            "Current correction result: people. Word: people\n",
            "Elements passed: 16000. Accuracy: 0.0912\n",
            "Current correction result: building. Word: building\n",
            "Elements passed: 17000. Accuracy: 0.0969\n",
            "Current correction result: dear. Word: hear\n",
            "Elements passed: 18000. Accuracy: 0.1028\n",
            "Current correction result: umm. Word: much\n",
            "Elements passed: 19000. Accuracy: 0.1088\n",
            "Current correction result: also. Word: so\n",
            "Elements passed: 20000. Accuracy: 0.1146\n",
            "Current correction result: he. Word: he\n",
            "Elements passed: 21000. Accuracy: 0.1202\n",
            "Current correction result: minutes. Word: minutes\n",
            "Elements passed: 22000. Accuracy: 0.1260\n",
            "Current correction result: was. Word: what\n",
            "Elements passed: 23000. Accuracy: 0.1319\n",
            "Current correction result: of. Word: of\n",
            "Elements passed: 24000. Accuracy: 0.1377\n",
            "Current correction result: last. Word: last\n",
            "Elements passed: 25000. Accuracy: 0.1435\n",
            "Current correction result: nat. Word: great\n",
            "Elements passed: 26000. Accuracy: 0.1492\n",
            "Current correction result: wags. Word: wages\n",
            "Elements passed: 27000. Accuracy: 0.1547\n",
            "Current correction result: s. Word: as\n",
            "Elements passed: 28000. Accuracy: 0.1601\n",
            "Current correction result: he. Word: the\n",
            "Elements passed: 29000. Accuracy: 0.1658\n",
            "Current correction result: center. Word: center\n",
            "Elements passed: 30000. Accuracy: 0.1714\n",
            "Current correction result: a. Word: to\n",
            "Elements passed: 31000. Accuracy: 0.1772\n",
            "Current correction result: o. Word: do\n",
            "Elements passed: 32000. Accuracy: 0.1829\n",
            "Current correction result: the. Word: the\n",
            "Elements passed: 33000. Accuracy: 0.1884\n",
            "Current correction result: to. Word: to\n",
            "Elements passed: 34000. Accuracy: 0.1939\n",
            "Current correction result: trial. Word: trial\n",
            "Elements passed: 35000. Accuracy: 0.1995\n",
            "Current correction result: luxury. Word: luxury\n",
            "Elements passed: 36000. Accuracy: 0.2053\n",
            "Current correction result: would. Word: would\n",
            "Elements passed: 37000. Accuracy: 0.2111\n",
            "Current correction result: the. Word: the\n",
            "Elements passed: 38000. Accuracy: 0.2166\n",
            "Current correction result: some. Word: more\n",
            "Elements passed: 39000. Accuracy: 0.2221\n",
            "Current correction result: to. Word: told\n",
            "Elements passed: 40000. Accuracy: 0.2279\n",
            "Current correction result: all. Word: deal\n",
            "Elements passed: 41000. Accuracy: 0.2334\n",
            "Current correction result: dime. Word: time\n",
            "Elements passed: 42000. Accuracy: 0.2391\n",
            "Current correction result: or. Word: for\n",
            "Elements passed: 43000. Accuracy: 0.2448\n",
            "Current correction result: call. Word: call\n",
            "Elements passed: 44000. Accuracy: 0.2505\n",
            "Current correction result: the. Word: the\n",
            "Elements passed: 45000. Accuracy: 0.2562\n",
            "Current correction result: just. Word: just\n",
            "Elements passed: 46000. Accuracy: 0.2622\n",
            "Current correction result: people. Word: people\n",
            "Elements passed: 47000. Accuracy: 0.2681\n",
            "Current correction result: off. Word: of\n",
            "Elements passed: 48000. Accuracy: 0.2738\n",
            "Current correction result: of. Word: of\n",
            "Elements passed: 49000. Accuracy: 0.2795\n",
            "Current correction result: court. Word: court\n",
            "Elements passed: 50000. Accuracy: 0.2853\n",
            "Current correction result: b. Word: up\n",
            "Elements passed: 51000. Accuracy: 0.2910\n",
            "Current correction result: tyco. Word: to\n",
            "Elements passed: 52000. Accuracy: 0.2968\n",
            "Current correction result: tm. Word: to\n",
            "Elements passed: 53000. Accuracy: 0.3024\n",
            "Current correction result: inn. Word: in\n",
            "Elements passed: 54000. Accuracy: 0.3081\n",
            "Current correction result: ave. Word: have\n",
            "Elements passed: 55000. Accuracy: 0.3138\n",
            "Current correction result: n't. Word: n't\n",
            "Elements passed: 56000. Accuracy: 0.3194\n",
            "Current correction result: know. Word: own\n",
            "Elements passed: 57000. Accuracy: 0.3255\n",
            "Current correction result: who. Word: of\n",
            "Elements passed: 58000. Accuracy: 0.3312\n",
            "Current correction result: gi. Word: give\n",
            "Elements passed: 59000. Accuracy: 0.3370\n",
            "Current correction result: new. Word: new\n",
            "Elements passed: 60000. Accuracy: 0.3423\n",
            "Current correction result: c. Word: to\n",
            "Elements passed: 61000. Accuracy: 0.3478\n",
            "Current correction result: possibility. Word: possibility\n",
            "Elements passed: 62000. Accuracy: 0.3535\n",
            "Current correction result: he. Word: had\n",
            "Elements passed: 63000. Accuracy: 0.3590\n",
            "Current correction result: he. Word: her\n",
            "Elements passed: 64000. Accuracy: 0.3646\n",
            "Current correction result: a. Word: to\n",
            "Elements passed: 65000. Accuracy: 0.3702\n",
            "Current correction result: bin. Word: in\n",
            "Elements passed: 66000. Accuracy: 0.3759\n",
            "Current correction result: car. Word: car\n",
            "Elements passed: 67000. Accuracy: 0.3817\n",
            "Current correction result: only. Word: only\n",
            "Elements passed: 68000. Accuracy: 0.3875\n",
            "Current correction result: o. Word: to\n",
            "Elements passed: 69000. Accuracy: 0.3932\n",
            "Current correction result: come. Word: come\n",
            "Elements passed: 70000. Accuracy: 0.3989\n",
            "Current correction result: it. Word: it\n",
            "Elements passed: 71000. Accuracy: 0.4047\n",
            "Current correction result: do. Word: to\n",
            "Elements passed: 72000. Accuracy: 0.4107\n",
            "Current correction result: matter. Word: matter\n",
            "Elements passed: 73000. Accuracy: 0.4164\n",
            "Current correction result: was. Word: was\n",
            "Elements passed: 74000. Accuracy: 0.4221\n",
            "Current correction result: zoo. Word: go\n",
            "Elements passed: 75000. Accuracy: 0.4275\n",
            "Current correction result: knee. Word: be\n",
            "Elements passed: 76000. Accuracy: 0.4332\n",
            "Current correction result: round. Word: round\n",
            "Elements passed: 77000. Accuracy: 0.4390\n",
            "Current correction result: ne. Word: make\n",
            "Elements passed: 78000. Accuracy: 0.4447\n",
            "Current correction result: and. Word: and\n",
            "Elements passed: 79000. Accuracy: 0.4505\n",
            "Current correction result: people. Word: people\n",
            "Elements passed: 80000. Accuracy: 0.4564\n",
            "Current correction result: that. Word: that\n",
            "Elements passed: 81000. Accuracy: 0.4621\n",
            "Current correction result: learn. Word: learn\n",
            "Elements passed: 82000. Accuracy: 0.4677\n",
            "Current correction result: it. Word: it\n",
            "Elements passed: 83000. Accuracy: 0.4735\n",
            "Current correction result: her. Word: her\n",
            "Elements passed: 84000. Accuracy: 0.4795\n",
            "Current correction result: a. Word: a\n",
            "Elements passed: 85000. Accuracy: 0.4852\n",
            "Current correction result: name. Word: name\n",
            "Elements passed: 86000. Accuracy: 0.4908\n",
            "Current correction result: it. Word: to\n",
            "Elements passed: 87000. Accuracy: 0.4966\n",
            "Current correction result: a. Word: a\n",
            "Elements passed: 88000. Accuracy: 0.5027\n",
            "Current correction result: it. Word: at\n",
            "Elements passed: 89000. Accuracy: 0.5085\n",
            "Current correction result: community. Word: community\n",
            "Elements passed: 90000. Accuracy: 0.5142\n",
            "Current correction result: expecting. Word: expecting\n",
            "Elements passed: 91000. Accuracy: 0.5200\n",
            "Current correction result: had. Word: had\n",
            "Elements passed: 92000. Accuracy: 0.5259\n",
            "Current correction result: both. Word: other\n",
            "Elements passed: 93000. Accuracy: 0.5315\n",
            "Current correction result: think. Word: think\n",
            "Elements passed: 94000. Accuracy: 0.5370\n",
            "Current correction result: n't. Word: n't\n",
            "Elements passed: 95000. Accuracy: 0.5430\n",
            "Current correction result: exact. Word: exact\n",
            "Elements passed: 96000. Accuracy: 0.5486\n",
            "Current correction result: want. Word: want\n",
            "Elements passed: 97000. Accuracy: 0.5543\n",
            "Current correction result: teh. Word: the\n",
            "Elements passed: 98000. Accuracy: 0.5600\n",
            "Current correction result: the. Word: the\n",
            "Elements passed: 99000. Accuracy: 0.5657\n",
            "Current correction result: long. Word: on\n",
            "Elements passed: 100000. Accuracy: 0.5714\n",
            "Current correction result: period. Word: period\n",
            "Elements passed: 101000. Accuracy: 0.5769\n",
            "Current correction result: a. Word: a\n",
            "Elements passed: 102000. Accuracy: 0.5826\n",
            "Current correction result: inn. Word: in\n",
            "Elements passed: 103000. Accuracy: 0.5882\n",
            "Current correction result: the. Word: the\n",
            "Upgraded Norvig Corrector accuracy of validation set: 0.5922\n"
          ]
        }
      ],
      "source": [
        "right_corrections_count = 0\n",
        "\n",
        "for val_row in tqdm(val_df.iterrows(), total=val_df.shape[0]):\n",
        "    word_idx = val_row[1].loc['modified_word_idxs']\n",
        "    modified_sent = val_row[1].loc['modified_sentence']\n",
        "    correction = ngram_norvig_corrector.correction(modified_sent[word_idx], modified_sent[:word_idx])# + modified_sent[word_idx + 1:])\n",
        "\n",
        "    if val_row[0] % 1000 == 0:\n",
        "        print(f\"Elements passed: {val_row[0]}. Accuracy: {(right_corrections_count / val_df.shape[0]):.4f}\")\n",
        "        print(f\"Current correction result: {correction}. Word: {val_row[1].loc['original_sent'][word_idx]}\")\n",
        "        \n",
        "    if val_row[1].loc['original_sent'][word_idx] == correction:\n",
        "        right_corrections_count += 1\n",
        "    \n",
        "print(f\"Upgraded Norvig Corrector accuracy of validation set: {(right_corrections_count / val_df.shape[0]):.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Conclusion & improvement thoughts\n",
        "As we can see, adding the N-Gram model and summing total probabilitites for each word improves accuracy a bit.\n",
        "From my point of view, in the future Norvig Correctors with N-Gram models implementations the following modifications can be applied:\n",
        "- Try to add weights to `word_proba` and `context_proba`;\n",
        "- Try to add weights to all error types;\n",
        "- Instead of adding weights to probabilities we can think of different formula for the resulting probability (Not a simple summation);\n",
        "- Many more... Imagination is the main limitation. And computing power + storage."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Useful resources (also included in the archive in moodle):\n",
        "\n",
        "1. [Possible dataset with N-grams](https://www.ngrams.info/download_coca.asp)\n",
        "2. [DamerauLevenshtein distance](https://en.wikipedia.org/wiki/DamerauLevenshtein_distance#:~:text=Informally%2C%20the%20DamerauLevenshtein%20distance,one%20word%20into%20the%20other.)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
